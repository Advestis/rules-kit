<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>ruleskit.ruleset API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ruleskit.ruleset</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import inspect
from abc import ABC
import ast
import pandas as pd
from copy import copy
from typing import List, Union, Tuple, Any, Optional
from collections import Counter
import numpy as np
import itertools
from collections import OrderedDict

from .condition import HyperrectangleCondition

from .rule import Rule, ClassificationRule, RegressionRule
from .activation import Activation
from .utils import rfunctions as functions
import logging
import warnings

from .utils.rfunctions import (
    calc_ruleset_prediction_weighted_regressor_stacked,
    calc_ruleset_prediction_weighted_classificator_stacked,
    calc_ruleset_prediction_equally_weighted_classificator_stacked,
    calc_ruleset_prediction_equally_weighted_regressor_stacked,
    calc_ruleset_prediction_weighted_regressor_unstacked,
    calc_ruleset_prediction_equally_weighted_regressor_unstacked,
    calc_ruleset_prediction_weighted_classificator_unstacked,
    calc_ruleset_prediction_equally_weighted_classificator_unstacked,
    calc_zscore_external,
)

logger = logging.getLogger(__name__)


class RuleSet(ABC):

    &#34;&#34;&#34;A set of rules&#34;&#34;&#34;

    NLINES = 5  # half how many rules to show in str(self)
    CHECK_DUPLICATED = False
    STACKED_FIT = False
    all_features_indexes = {}
    attributes_from_train_set = {ClassificationRule: [&#34;train_set_size&#34;], RegressionRule: [&#34;train_set_size&#34;]}
    attributes_from_test_set = {
        ClassificationRule: [&#34;criterion&#34;, &#34;test_set_size&#34;], RegressionRule: [&#34;criterion&#34;, &#34;test_set_size&#34;]
    }

    @staticmethod
    def check_duplicated_rules(rules, name_or_index: str = &#34;index&#34;):
        if name_or_index == &#34;index&#34;:
            str_rules = [str(r.features_indexes) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in rules]
        else:
            str_rules = [str(r.features_names) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in rules]
        if len(set(str_rules)) &lt; len(str_rules):
            duplicated = {}
            for r in str_rules:
                if r not in duplicated:
                    duplicated[r] = 0
                duplicated[r] += 1
            duplicated = [
                f&#34;{r}: {duplicated[r]} (positions {[i for i, x in enumerate(str_rules) if x == r]})\n&#34;
                f&#34;   underlying rules : {[str(rules[i]) for i in [i for i, x in enumerate(str_rules) if x == r]]}&#34;
                for r in duplicated
                if duplicated[r] &gt; 1
            ]
            s = &#34;\n -&#34;.join(duplicated)
            raise ValueError(f&#34;There are {len(duplicated)} duplicated rules in your ruleset !\n {s}&#34;)

    def __init__(
        self,
        rules_list: Union[List[Rule], None] = None,
        compute_activation: bool = True,
        stack_activation: bool = False,
    ):
        &#34;&#34;&#34;

        Parameters
        ----------
        rules_list: Union[List[Rule], None]
            The list of rules to start with. Can be None, since a RuleSet can be filled after its creation.
        compute_activation: bool
            The activation of the RuleSet is the logical OR of the activation of all its rules. It is only computed
            if compute_activation is True. (default value = True)
        stack_activation: bool
            If True, the RuleSet will keep in memory 2-D np.ndarray containing the activations of all its rules. This
            can take a lot of memory, but can save time if you apply numpy methods on this stacked vector instead of on
            each rule separately. (default value = False)
        &#34;&#34;&#34;
        self._rules: List[Rule] = []
        self.features_names: List[str] = []
        self.features_indexes: List[int] = []
        self._activation: Optional[Activation] = None
        self._coverage: Optional[float] = None  # in case Activation is not available
        self.criterion: Optional[float] = None
        self.train_set_size: Optional[int] = None
        self.test_set_size: Optional[int] = None
        &#34;&#34;&#34;Set by self.eval&#34;&#34;&#34;
        self.stacked_activations: Optional[pd.DataFrame] = None
        self.stack_activation: bool = stack_activation
        self._rule_type = None
        self._compute_activation = True  # Should NOT be equal to given compute_activation argument, but always True.
        if rules_list is not None:
            names_available = all([hasattr(r.condition, &#34;features_names&#34;) for r in self])
            for rule in rules_list:
                if not isinstance(rule, Rule) and rule is not None:
                    raise TypeError(f&#34;Some rules in given iterable were not of type &#39;Rule&#39; but of type {type(rule)}&#34;)
                if rule is not None:
                    self.append(rule, update_activation=False)
            if compute_activation:
                self.compute_self_activation()
            if self.stack_activation:
                self.compute_stacked_activation()
            if names_available:
                self.features_names = list(set(itertools.chain(*[rule.features_names for rule in self])))
            self.set_features_indexes()
        if self.__class__.CHECK_DUPLICATED:
            self.check_duplicated_rules(self.rules, name_or_index=&#34;name&#34; if len(self.features_names) &gt; 0 else &#34;index&#34;)

    # noinspection PyProtectedMember,PyTypeChecker
    def __iadd__(self, other: Union[&#34;RuleSet&#34;, Rule]):
        &#34;&#34;&#34;Appends a rule or each rules of another RuleSet to self and updates activation vector and stacked activations
        if needed. Also updates features_indexes, and features_names if possible.&#34;&#34;&#34;
        if isinstance(other, Rule):
            self._rules.append(other)
        else:
            self._rules += other._rules
        self.features_indexes = list(set(self.features_indexes + other.features_indexes))
        if hasattr(other, &#34;features_names&#34;):
            self.features_names = list(set(self.features_names + other.features_names))
        if self._compute_activation:
            self._update_activation(other)
        if self.stack_activation:
            self._update_stacked_activation(other)
        return self

    def __add__(self, other: Union[&#34;RuleSet&#34;, Rule]):
        &#34;&#34;&#34;Returns the RuleSet resulting in appendind a rule or each rules of another RuleSet to self.&#34;&#34;&#34;
        stack_activation = self.stack_activation
        if isinstance(other, Rule):
            rules = self.rules + [other]
        else:
            stack_activation &amp;= other.stack_activation
            rules = list(set(self.rules + other.rules))
        return self.__class__(rules, compute_activation=self._compute_activation, stack_activation=stack_activation)

    def __getattr__(self, item):
        &#34;&#34;&#34;If item is not found in self, try to fetch it from its activation.&#34;&#34;&#34;
        if item == &#34;_activation&#34;:
            raise AttributeError(f&#34;&#39;RuleSet&#39; object has no attribute &#39;{item}&#39;&#34;)

        if self._activation is not None and hasattr(self._activation, item):
            return getattr(self._activation, item)
        raise AttributeError(f&#34;&#39;RuleSet&#39; object has no attribute &#39;{item}&#39;&#34;)

    def __len__(self):
        &#34;&#34;&#34;The length of a RuleSet its the number of rules stored in it.&#34;&#34;&#34;
        return len(self.rules)

    def __eq__(self, other: &#34;RuleSet&#34;):
        return set(self.rules) == set(other.rules)

    def __iter__(self):
        if hasattr(self, &#34;_rules&#34;):
            return self.rules.__iter__()
        else:
            return [].__iter__()

    def __getitem__(self, key):
        if isinstance(key, slice):
            indices = range(*key.indices(len(self.rules)))
            return self.__class__([self.rules[i] for i in indices])
        return self.rules.__getitem__(key)

    def __str__(self):
        if len(self) &lt; 2 * self.__class__.NLINES:
            return &#34;\n&#34;.join([str(self[i]) for i in range(len(self))])
        else:
            return &#34;\n&#34;.join(
                [str(self[i]) for i in range(self.__class__.NLINES)]
                + [&#34;...&#34;]
                + [str(self[i]) for i in range(len(self) - self.__class__.NLINES, len(self))]
            )

    def __hash__(self) -&gt; hash:
        return hash(frozenset(self.to_hash))

    # noinspection PyProtectedMember
    def __contains__(self, other: Rule) -&gt; bool:
        &#34;&#34;&#34;A RuleSet contains another Rule if the two rule&#39;s conditions and predictions are the same&#34;&#34;&#34;
        name_or_index = &#34;name&#34; if len(self.features_names) &gt; 0 else &#34;index&#34;

        if name_or_index == &#34;index&#34;:
            str_rules = [str(r.features_indexes) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in self]
            str_rule = str(other.features_indexes) + str(other.bmins) + str(other.bmaxs) + str(other.prediction)
        else:
            str_rules = [str(r.features_names) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in self]
            str_rule = str(other.features_names) + str(other.bmins) + str(other.bmaxs) + str(other.prediction)

        return str_rule in str_rules

    @property
    def rule_type(self) -&gt; type:
        if self._rule_type is None:
            raise ValueError(&#34;Ruleset&#39;s rule type is not set !&#34;)
        return self._rule_type

    @rule_type.setter
    def rule_type(self, rule_type: type):
        if not issubclass(rule_type, (ClassificationRule, RegressionRule, Rule)):
            raise TypeError(
                &#34;Ruleset&#39;s rule type must be a subclass of ruleskit.RegressionRule or ruleskit.ClassificationRule, not&#34;
                f&#34; {rule_type}&#34;
            )
        self._rule_type = rule_type

    @property
    def rules(self) -&gt; List[Rule]:
        return self._rules

    @rules.setter
    def rules(self, rules: Union[List[Rule], None]):
        ruleset = RuleSet(rules, stack_activation=self.stack_activation)
        self._rules = ruleset._rules
        self.features_names = ruleset.features_names
        self.features_indexes = ruleset.features_indexes
        self.stacked_activations = ruleset.stacked_activations
        self._activation = ruleset._activation

    @property
    def to_hash(self) -&gt; Tuple[str]:
        if len(self) == 0:
            return &#34;rs&#34;,
        to_hash = (&#34;rs&#34;,)
        for r in self:
            rule_hash = r.to_hash[1:]
            to_hash += rule_hash
        return to_hash

    @property
    def activation_available(self) -&gt; bool:
        &#34;&#34;&#34;Returns True if the RuleSet has an activation vector, and if this Activation&#39;s object data is available.&#34;&#34;&#34;
        if self._activation is None or self._activation.length == 0:
            return False
        if self._activation.data_format == &#34;file&#34;:
            return self._activation.data.is_file()
        else:
            return self._activation.data is not None

    @property
    def stacked_activations_available(self) -&gt; bool:
        &#34;&#34;&#34;Returns True is the RuleSet has its rules&#39; stacked activations.&#34;&#34;&#34;
        if self.stack_activation is None or self._activation.length == 0:
            return False
        return True

    @property
    def activation(self) -&gt; Union[None, np.ndarray]:
        &#34;&#34;&#34;Returns the Activation vector&#39;s data in a form of a 1-D np.ndarray, or None if not available.

        Returns:
        --------
        Union[None, np.ndarray]
            of the form [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, ...]
        &#34;&#34;&#34;
        if self._activation:
            return self._activation.raw
        return None

    @property
    def ruleset_coverage(self) -&gt; float:
        &#34;&#34;&#34;Coverage is the fraction of points equal to 1 in the activation vector&#34;&#34;&#34;
        if not self.activation_available:
            return self._coverage
        else:
            return self._activation.coverage

    # noinspection PyProtectedMember,PyTypeChecker
    def _update_activation(self, other: Union[Rule, &#34;RuleSet&#34;]):
        &#34;&#34;&#34;Updates the activation vector of the RuleSet with the activation vector of a new Rule or RuleSet.&#34;&#34;&#34;
        if other.activation_available:
            if self._activation is None or self._activation.length == 0:
                self._activation = Activation(other.activation, to_file=Rule.LOCAL_ACTIVATION)
            else:
                self._activation = self._activation | other._activation

    # noinspection PyProtectedMember,PyTypeChecker
    def _update_stacked_activation(self, other: Union[Rule, &#34;RuleSet&#34;]):
        &#34;&#34;&#34;Updates the stacked activation vectors of the RuleSet with the activation vector of a new Rule or
        the stacked activation vectors of another RuleSet.&#34;&#34;&#34;
        if other.activation_available:

            if self.stacked_activations is None:
                if isinstance(other, Rule):
                    self.stacked_activations = pd.DataFrame(
                        data=np.array(other.activation).T, columns=[str(other.condition)]
                    )
                else:
                    self.stacked_activations = other.stacked_activations
            else:
                if isinstance(other, Rule):
                    self.stacked_activations[str(other.condition)] = other.activation
                else:
                    self.stacked_activations = pd.concat([self.stacked_activations, other.stacked_activations], axis=1)

    def set_features_indexes(self):
        if len(self.__class__.all_features_indexes) &gt; 0:
            self.features_indexes = [self.__class__.all_features_indexes[f] for f in self.features_names]
            for r in self._rules:
                # noinspection PyProtectedMember
                r._condition._features_indexes = [self.__class__.all_features_indexes[f] for f in r.features_names]
        else:
            list(set(itertools.chain(*[rule.features_indexes for rule in self])))

    # noinspection PyProtectedMember
    def fit(
        self,
        y: Union[np.ndarray, pd.Series],
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        force_if_not_good: bool = False,
        **kwargs,
    ) -&gt; List[Rule]:
        &#34;&#34;&#34;Fits the ruleset on y and xs to produce the rules&#39; activation vectors and attributes relevant to train set.

        Parameters
        ----------
        y: Union[np.ndarray, pd.Series]
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
        force_if_not_good: bool
        kwargs

        Returns
        -------
        List[Rule]
            List of rules that were excluded from the ruleset after fitting because they were &#39;bad&#39;
        &#34;&#34;&#34;
        if issubclass(self.rule_type, ClassificationRule):
            type_to_use = ClassificationRule
        elif issubclass(self.rule_type, RegressionRule):
            type_to_use = RegressionRule
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

        if &#34;method&#34; in kwargs:
            raise IndexError(&#34;Key &#39;method&#39; can not be given to &#39;fit&#39;&#34;)

        def launch_method(method, **kw):
            expected_args = list(inspect.signature(method).parameters)
            if &#34;kwargs&#34; not in expected_args:
                kw = {item: kw[item] for item in kw if item in expected_args}
            return method(**kw)

        if xs is not None and len(xs) == 0:
            logger.warning(&#34;Given xs is empty&#34;)
            return []

        if len(self) == 0:
            logger.debug(&#34;Ruleset is empty. Nothing to fit.&#34;)
            return []

        if all([r._fitted for r in self]) and xs is None:
            return []

        if self.__class__.STACKED_FIT:

            clean_activation = False
            # Activation must always be computed from train set
            if xs is not None:
                clean_activation = not self.stack_activation
                self.stack_activation = True
                self.calc_activation(xs)
                self.stack_activation = not clean_activation
            elif self.stacked_activations is None:
                clean_activation = not self.stack_activation
                self.stack_activation = True
                self.compute_stacked_activation()
                self.stack_activation = not clean_activation

            if isinstance(y, np.ndarray):
                # noinspection PyUnresolvedReferences
                if not len(self.stacked_activations.index) == y.shape[0]:
                    raise IndexError(
                        &#34;Stacked activation and y have different number of rows. Use pd.Series for y to&#34;
                        &#34; reindex stacked activations automatically.&#34;
                    )
            else:
                self.stacked_activations.index = y.index

            computed_attrs = {}
            # noinspection PyUnresolvedReferences
            for attr in self.rule_type.attributes_from_train_set:
                if attr == &#34;activation&#34;:
                    raise ValueError(&#34;&#39;activation&#39; can not be specified in &#39;attributes_from_train_set&#39;&#34;)
                computed_attrs[f&#34;{attr}s&#34;] = launch_method(
                    getattr(self, f&#34;calc_{attr}s&#34;), y=y, xs=xs, **computed_attrs, **kwargs
                )
            to_drop = []

            if clean_activation:
                self.del_stacked_activations()
            else:
                if isinstance(y, np.ndarray):
                    self.stacked_activations.index = pd.RangeIndex(y.shape[0])
                else:
                    self.stacked_activations.index = pd.RangeIndex(len(y.index))

            for ir in range(len(self)):
                self._rules[ir]._fitted = True
                for attr in computed_attrs:
                    setattr(self._rules[ir], f&#34;_{attr[:-1]}&#34;, computed_attrs[attr].iloc[ir])
                    if self._rules[ir].good:
                        self._rules[ir].check_thresholds(attr[:-1])
                    if not self._rules[ir].good:
                        to_drop.append(self._rules[ir])
                # To check attributes that are set along side others, like coverage
                if self._rules[ir].good:
                    self._rules[ir].check_thresholds()
        else:
            [r.fit(xs=xs, y=y, force_if_not_good=force_if_not_good, **kwargs) for r in self]
            to_drop = [r for r in self if not r.good]

        if len(to_drop) &gt; 0:
            rules = [r for r in self.rules if r not in to_drop]
            self._rules = []
            if self._activation is not None:
                self._activation.clear()
            self.del_stacked_activations()
            for r in rules:
                self.append(r, update_activation=False)

            # Recompute activation now that bad rules have been droped
            self._activation = None
            self.compute_self_activation()
            if self.stack_activation:
                self.stacked_activations = None
                self.compute_stacked_activation()
        # If not bad rules were dropped and stacked fit was not used, still compute self.activation since it has not
        # been done  (needed to set self.coverage), but not stacked (useless)
        elif not self.__class__.STACKED_FIT:
            if self._activation is None or self._activation.length == 0 or xs is not None:
                self._activation = None
                self.compute_self_activation()
            if self.stack_activation and (self.stacked_activations is None or xs is not None):
                self.stacked_activations = None
                self.compute_stacked_activation()

        for attr in self.__class__.attributes_from_train_set[type_to_use]:
            launch_method(
                getattr(self, f&#34;calc_{attr}&#34;),
                y=y,
                xs=xs,
                **kwargs,
            )

        return to_drop

    # noinspection PyProtectedMember
    def eval(
        self,
        y: Union[np.ndarray, pd.Series],
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        keep_new_activations: bool = False,
        weights: Optional[Union[pd.Series, str]] = None,
        force_if_not_good: bool = False,
        **kwargs,
    ) -&gt; List[Rule]:
        &#34;&#34;&#34;Evaluate the ruleset on y and xs to produce the rules&#39; attributes relevant to the test set. Will recompute
        the ruleset&#39;s stacked activation vector if using stakced fit.

        Parameters
        ----------
        y: Union[np.ndarray, pd.Series]
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
        keep_new_activations: bool
            If True, activation vectgor and stacked activation vectors will be kept as ruleset&#39;s attribute and replace
            the ones computed using the train set, if any. Will also change the activation vectors of the rules.
        weights: Optional[Union[pd.Series, str]]
            Optional weights for calc_critetion. If is a pd.Series, expects the index to be the rules names.
            If is a str, a pd.Series will be constructed by fetching each rules&#39; attribute named after the given string
            (ex: it can be &#39;criterion&#39;)
        force_if_not_good: bool
            If the rule was seen as &#34;bad&#34;, eval will not trigger unless this boolean is True (Default value = False)
        kwargs


        Returns
        -------
        List[Rule]
            List of rules that were excluded from the ruleset after fitting because they were &#39;bad&#39;
        &#34;&#34;&#34;
        if issubclass(self.rule_type, ClassificationRule):
            type_to_use = ClassificationRule
        elif issubclass(self.rule_type, RegressionRule):
            type_to_use = RegressionRule
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

        if &#34;method&#34; in kwargs:
            raise IndexError(&#34;Key &#39;method&#39; can not be given to &#39;eval&#39;&#34;)

        def launch_method(method, **kw):
            expected_args = list(inspect.signature(method).parameters)
            if &#34;kwargs&#34; not in expected_args:
                kw = {item: kw[item] for item in kw if item in expected_args}
            return method(**kw)

        if xs is not None and len(xs) == 0:
            logger.warning(&#34;Given xs is empty&#34;)
            return []

        if len(self) == 0:
            logger.debug(&#34;Ruleset is empty. Nothing to fit.&#34;)
            return []

        if not all([r._fitted for r in self]):
            if xs is None:
                raise ValueError(
                    &#34;Not all rules of the ruleset were fitted. Please do so before calling ruleset.eval or provide xs.&#34;
                )
            else:
                keep_new_activations = True

        if self.__class__.STACKED_FIT:
            clean_activation = False

            # If test set is given, compute the activation used to evaluate test relative attributes.
            # Not the same as self.stacked_activations, computed from the train set.
            # Else, we evaluate on the train set, so we use self.stacked_actviation
            nones = None
            if xs is not None:
                if keep_new_activations:
                    clean_activation = not self.stack_activation
                    self.stack_activation = True
                    self.calc_activation(xs=xs)  # Will reset rules&#39; activation vectors too
                    self.stack_activation = not clean_activation
                    stacked_activations = self.stacked_activations
                    activation = self._activation
                    # noinspection PyUnresolvedReferences
                    if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                        nones = pd.Series({str(r.condition): r.nones for r in self})
                else:
                    stacked_activations = self.evaluate_stacked_activations(xs)
                    # noinspection PyUnresolvedReferences
                    if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                        activation, nones = self.evaluate_self_activation(xs, return_nones=True)
                    else:
                        activation = self.evaluate_self_activation(xs)
            else:
                # If self.stacked_activations is None, compute it from the rules&#39; activations. They must be available.
                if self.stacked_activations is None:
                    # Else, will compute the stacked activation from the current rules activations
                    clean_activation = not self.stack_activation
                    self.stack_activation = True
                    self.compute_stacked_activation()
                    self.compute_self_activation()
                    if self.stacked_activations is None:
                        raise ValueError(&#34;Rules activations must have been computed previously.&#34;)
                    self.stack_activation = not clean_activation
                stacked_activations = self.stacked_activations
                activation = self._activation
                # noinspection PyUnresolvedReferences
                if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                    nones = pd.Series({str(r.condition): r.nones for r in self})

            if isinstance(y, np.ndarray):
                if not len(stacked_activations.index) == y.shape[0]:
                    raise IndexError(&#34;Stacked activation and y have different number of rows.&#34;)
            else:
                if not len(stacked_activations.index) == len(y.index):
                    raise IndexError(&#34;Stacked activation and y have different number of rows.&#34;)
                stacked_activations.index = y.index

            # noinspection PyUnresolvedReferences
            if &#34;prediction&#34; in self.rule_type.attributes_from_train_set:
                # Do NOT recompute prediction from test set : it does not make sense !
                predictions = pd.Series({str(r.condition): r.prediction for r in self})
            else:
                predictions = None
            computed_attrs = {}

            # noinspection PyUnresolvedReferences
            for attr in self.rule_type.attributes_from_test_set:
                if attr == &#34;activation&#34;:
                    raise ValueError(&#34;&#39;activation&#39; can not be specified in &#39;attributes_from_train_set&#39;&#34;)
                computed_attrs[f&#34;{attr}s&#34;] = launch_method(
                    getattr(self, f&#34;calc_{attr}s&#34;),
                    y=y,
                    xs=xs,
                    stacked_activations=stacked_activations,
                    activation=activation,
                    nones=nones,
                    predictions=predictions,
                    **computed_attrs,
                    **kwargs,
                )

            to_drop = []

            if clean_activation:
                self.del_stacked_activations()
            else:
                if isinstance(y, np.ndarray):
                    stacked_activations.index = pd.RangeIndex(y.shape[0])
                else:
                    stacked_activations.index = pd.RangeIndex(len(y.index))

            for ir in range(len(self)):
                self._rules[ir]._evaluated = True
                for attr in computed_attrs:
                    setattr(self._rules[ir], f&#34;_{attr[:-1]}&#34;, computed_attrs[attr].iloc[ir])
                    if self._rules[ir].good:
                        self._rules[ir].check_thresholds(attr[:-1])
                    if not self._rules[ir].good:
                        to_drop.append(self._rules[ir])
                if self._rules[ir].good:
                    self._rules[ir].check_thresholds()
        else:
            [
                r.eval(
                    xs=xs, y=y, recompute_activation=keep_new_activations,
                    force_if_not_good=force_if_not_good, **kwargs
                ) for r in self
            ]
            to_drop = [r for r in self if not r.good]

        if len(to_drop) &gt; 0:
            rules = [r for r in self.rules if r not in to_drop]
            self._rules = []
            if self._activation is not None:
                self._activation.clear()
            self.del_stacked_activations()
            for r in rules:
                self.append(r, update_activation=False)

            # Recompute activation now that bad rules have been droped
            if self._activation is None or self._activation.length == 0 or (xs is not None and keep_new_activations):
                self._activation = None
                self.compute_self_activation()
            if self.stack_activation and (
                self.stacked_activations is None or (xs is not None and keep_new_activations)
            ):
                self.stacked_activations = None
                self.compute_stacked_activation()
        # If not bad rules were dropped and stacked fit was not used, still compute self.activation since it has not
        # been done
        elif not self.__class__.STACKED_FIT:
            if self._activation is None or self._activation.length == 0 or (xs is not None and keep_new_activations):
                self._activation = None
                self.compute_self_activation()
            if self.stack_activation and (self._activation is None or (xs is not None and keep_new_activations)):
                self.stacked_activations = None
                self.compute_stacked_activation()

        for attr in self.__class__.attributes_from_test_set[type_to_use]:
            launch_method(
                getattr(self, f&#34;calc_{attr}&#34;),
                y=y,
                xs=xs if not keep_new_activations else None,
                weights=weights,
                **kwargs,
            )

        return to_drop

    def append(self, rule: Rule, update_activation: bool = True):
        &#34;&#34;&#34;Appends a new rule to self. The updates of activation vector and the stacked activation vectors can be
        blocked by specifying update_activation=False. Otherwise, will use self.stack_activation to determine if the
        updates should be done or not.&#34;&#34;&#34;
        if not isinstance(rule, Rule):
            raise TypeError(f&#34;RuleSet&#39;s append method expects a Rule object, got {type(rule)}&#34;)
        if self._rule_type is None:
            self.rule_type = type(rule)
        else:
            if not isinstance(rule, self.rule_type):
                raise TypeError(
                    f&#34;Ruleset previously had rules of type {self.rule_type}, so can not add rule of type {type(rule)}&#34;
                )
        stack_activation = self.stack_activation
        if not update_activation:
            self._compute_activation = False
            self.stack_activation = False
        self.__iadd__(rule)
        self._compute_activation = True
        self.stack_activation = stack_activation

    def sort(self, criterion: str = None, reverse: bool = False):
        &#34;&#34;&#34;Sorts the RuleSet.

        * If criterion is not speficied:
            Will sort the rules according to :
                1. The number of features they talk about
                2. For a same number of features (sorted in alphabetical order, or index if names are not available,
                    optionally reversed), the bmins and bmaxs of the rules
        * If criterion is specified, it must be an float or interger attribute of rule, condition or activation. Then
            sorts according to this criterion, optionally reversed.
        &#34;&#34;&#34;
        if len(self) == 0:
            return

        if criterion is None or criterion == &#34;&#34;:
            if not (hasattr(self[0].condition, &#34;bmins&#34;) and hasattr(self[0].condition, &#34;bmaxs&#34;)):
                return
            # The set of all the features the RuleSet talks about
            which = &#34;index&#34;
            if len(self.features_names) &gt; 0:
                which = &#34;name&#34;
                fnames_or_indexes = list(set([str(r.features_names) for r in self]))
            else:
                fnames_or_indexes = list(set([str(r.features_indexes) for r in self]))
            dict_names = {}
            lmax = 1
            for f in fnames_or_indexes:
                l_ = len(ast.literal_eval(f))
                if l_ &gt; lmax:
                    lmax = l_
                if l_ not in dict_names:
                    dict_names[l_] = []
                dict_names[l_].append(f)
            for l_ in dict_names:
                dict_names[l_].sort(reverse=reverse)
            fnames_or_indexes = []
            for l_ in range(1, lmax + 1):
                if l_ in dict_names:
                    fnames_or_indexes += dict_names[l_]

            rules_by_fnames = OrderedDict({f: [] for f in fnames_or_indexes})
            for rule in self:
                if which == &#34;name&#34;:
                    v = str(rule.features_names)
                else:
                    v = str(rule.features_indexes)
                rules_by_fnames[v].append(rule)
            rules_by_fnames = {
                n: sorted(rules_by_fnames[n], key=lambda x: x.condition.bmins + x.condition.bmaxs)
                for n in rules_by_fnames
            }
            self._rules = []
            for n in rules_by_fnames:
                self._rules += rules_by_fnames[n]
        elif hasattr(self[0], criterion):
            self._rules = sorted(self, key=lambda x: getattr(x, criterion), reverse=reverse)
        else:
            raise ValueError(f&#34;Can not sort RuleSet according to criterion {criterion}&#34;)
        if self.stack_activation:
            self.stacked_activations = self.stacked_activations[[str(r.condition) for r in self]]

    # noinspection PyProtectedMember
    def evaluate_self_activation(
            self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None, return_nones: bool = False
    ):
        &#34;&#34;&#34;Computes the activation vector of self from its rules, using time-efficient Activation.multi_logical_or.&#34;&#34;&#34;
        if len(self) == 0:
            act = Activation(np.array([]))
            if return_nones is True:
                return act, pd.Series(dtype=int)
            return act
        if xs is not None:
            activations = [r.evaluate_activation(xs) for r in self]
            activations_available = True
        else:
            activations = [r._activation for r in self]
            activations_available = all([r.activation_available for r in self])
        if activations_available:
            if len(self) == 1:
                act = Activation(activations[0].raw, optimize=activations[0].optimize, to_file=activations[0].to_file)
                if return_nones is True:
                    return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
                return act
            try:
                act = Activation.multi_logical_or(activations)
                if return_nones is True:
                    return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
                return act
            except (MemoryError, np.core._exceptions._ArrayMemoryError):
                act = Activation(activations[0], optimize=activations[0].optimize, to_file=activations[0].to_file)
                for a in activations:
                    act = act or a
                if return_nones is True:
                    return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
                return act

    def compute_self_activation(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
        &#34;&#34;&#34;Computes the activation vector of self from its rules. If xs is specified, uses it to remake the
        rules&#39; activation vectors, but do not set them as the &#39;activation&#39; attributes of the rules&#34;&#34;&#34;
        self._activation = self.evaluate_self_activation(xs=xs)

    def evaluate_stacked_activations(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
        if len(self) == 0:
            return pd.DataFrame(dtype=int)
        if xs is not None:
            return pd.DataFrame({str(r.condition): r.evaluate_activation(xs).raw for r in self})
        activations_available = all([r.activation_available for r in self])
        if activations_available:
            # noinspection PyProtectedMember
            return pd.DataFrame({str(r.condition): r.activation for r in self})

    def compute_stacked_activation(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
        &#34;&#34;&#34;Computes the stacked activation vectors of self from its rules. If xs is specified, uses it to remake the
        rules&#39; activation vectors, but do not set them as the &#39;activation&#39; attributes of the rules&#34;&#34;&#34;
        self.stacked_activations = self.evaluate_stacked_activations(xs=xs)

    def del_activations(self):
        &#34;&#34;&#34;Deletes the data, but not the relevent attributes, of the activation vector or each rules in self.&#34;&#34;&#34;
        for r in self:
            r.del_activation()

    def del_activation(self):
        &#34;&#34;&#34;Deletes the activation vector&#39;s data of self, but not the object itself, so any computed attribute remains
        available&#34;&#34;&#34;
        if hasattr(self, &#34;_activation&#34;) and self._activation is not None:
            self._activation.delete()

    def del_stacked_activations(self):
        &#34;&#34;&#34;Deletes stacked activation vectors of self. Set it to None.&#34;&#34;&#34;
        if hasattr(self, &#34;stacked_activations&#34;) and self.stacked_activations is not None:
            del self.stacked_activations
            self.stacked_activations = None

    def evaluate(self, xs: Union[pd.DataFrame, np.ndarray]) -&gt; Activation:
        &#34;&#34;&#34;Computes and returns the activation vector from an array of features.

        Parameters
        ----------
        xs: Union[pd.DataFrame, np.ndarray]
            The features on which the check whether the rule is activated or not. Must be a 2-D np.ndarray
            or pd.DataFrame.

        Returns
        -------
        Activation
        &#34;&#34;&#34;
        if len(self) == 0:
            raise ValueError(&#34;Can not use evaluate : The ruleset is empty!&#34;)
        activations = [rule.evaluate_activation(xs) for rule in self.rules]
        return Activation.multi_logical_or(activations)

    def calc_activation(self, xs: Union[np.ndarray, pd.DataFrame]):
        &#34;&#34;&#34;Uses input xs features data to compute the activation vector of all rules in self, and updates self&#39;s
        activation and stacked activation if self.stack_activation is True

        Parameters
        ----------
        xs: Union[np.ndarray, pd.DataFrame]
        &#34;&#34;&#34;
        if len(self) == 0:
            raise ValueError(&#34;Can not use calc_activation : The ruleset is empty!&#34;)

        if len(xs) == 0:
            logger.warning(&#34;Given xs is empty&#34;)
            return
        [rule.calc_activation(xs) for rule in self.rules]

        self._activation = None
        self.compute_self_activation()
        if self.stack_activation:
            self.stacked_activations = None
            self.compute_stacked_activation()

    def get_features_count(self) -&gt; List[Tuple[Any, int]]:
        &#34;&#34;&#34;
        Get a counter of all different features in the ruleset. If names are not available, will use indexes.

        Returns:
        --------
        count : List[Tuple[Any, int]]
            Counter of all different features in the ruleset
        &#34;&#34;&#34;
        if len(self) == 0:
            return []
        if len(self.features_names) &gt; 0:
            var_in = list(itertools.chain(*[rule.features_names for rule in self]))
        else:
            var_in = list(itertools.chain(*[rule.feautres_indexes for rule in self]))
        count = Counter(var_in)

        count = count.most_common()
        return count

    def load(self, path, **kwargs):
        if hasattr(path, &#34;read&#34;):
            rules = path.read(**kwargs)
        else:
            rules = pd.read_csv(path, **kwargs)
        if &#34;ruleset coverage&#34; in rules.iloc[:, 0].values:
            self._coverage = rules[rules.iloc[:, 0] == &#34;ruleset coverage&#34;].iloc[0, 1]
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset coverage&#34;].index)
        if &#34;ruleset criterion&#34; in rules.iloc[:, 0].values:
            self.criterion = rules[rules.iloc[:, 0] == &#34;ruleset criterion&#34;].iloc[0, 1]
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset criterion&#34;].index)
        if &#34;ruleset train set size&#34; in rules.iloc[:, 0].values:
            self.train_set_size = rules[rules.iloc[:, 0] == &#34;ruleset train set size&#34;].iloc[0, 1]
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset train set size&#34;].index)
            if isinstance(self.train_set_size, str):
                self.train_set_size = int(self.train_set_size)
        if &#34;ruleset test set size&#34; in rules.iloc[:, 0].values:
            self.test_set_size = rules[rules.iloc[:, 0] == &#34;ruleset test set size&#34;].iloc[0, 1]
            if isinstance(self.test_set_size, str):
                self.test_set_size = int(self.test_set_size)
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset test set size&#34;].index)
        if rules.empty:
            self._rules = []
        else:
            self._rules = [self.series_to_rule(rules.loc[r]) for r in rules.index]
        for r in self:
            if r._train_set_size is None:
                r._train_set_size = self.train_set_size
            elif isinstance(r._train_set_size, str):
                r._train_set_size = int(r._train_set_size)
            if r._test_set_size is None:
                r._test_set_size = self.test_set_size
            elif isinstance(r._test_set_size, str):
                r._test_set_size = int(r._test_set_size)

        if len(self._rules) &gt; 0:
            self.rule_type = type(self._rules[0])
        self.compute_self_activation()
        if self.stack_activation:
            self.compute_stacked_activation()
        self.features_names = list(set(traverse([rule.features_names for rule in self])))

    def to_df(self) -&gt; pd.DataFrame:
        if len(self) == 0:
            return pd.DataFrame()
        idx = copy(self._rule_type.index)

        dfs = [
            self.rule_to_series(
                (i, r),
                index=idx,
            )
            for i, r in enumerate(self.rules)
        ]
        if len(dfs) &gt; 0:
            df = pd.concat(dfs, axis=1).T
        else:
            df = pd.DataFrame(columns=idx)

        s_cov = pd.DataFrame(
            columns=df.columns,
            data=[[self.ruleset_coverage if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset coverage&#34;],
        )
        s_crit = pd.DataFrame(
            columns=df.columns,
            data=[[self.criterion if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset criterion&#34;],
        )
        s_train = pd.DataFrame(
            columns=df.columns,
            data=[[self.train_set_size if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset train set size&#34;],
        )
        s_test = pd.DataFrame(
            columns=df.columns,
            data=[[self.train_set_size if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset test set size&#34;],
        )
        return pd.concat([df, s_cov, s_crit, s_train, s_test])

    def save(self, path):
        df = self.to_df()

        if hasattr(path, &#34;write&#34;):
            path.write(df)
        else:
            df.to_csv(path)

    # noinspection PyProtectedMember
    @staticmethod
    def rule_to_series(irule: Tuple[int, Rule], index: list) -&gt; pd.Series:
        i = irule[0]
        rule = irule[1]
        if hasattr(rule, &#34;sign&#34;):
            name = f&#34;R_{i}({len(rule)}){rule.sign}&#34;
        else:
            name = f&#34;R_{i}({len(rule)})&#34;
        sr = pd.Series(data=[str(getattr(rule, ind)) for ind in index], name=name, index=index, dtype=str)
        return sr

    @staticmethod
    def series_to_rule(srule: pd.Series) -&gt; Rule:

        for ind in srule.index:
            if ind == &#34;Unnamed: 0&#34;:
                continue
            if ind not in Rule.index and ind not in RegressionRule.index and ind not in ClassificationRule.index:
                raise IndexError(f&#34;Invalid rule attribute &#39;{ind}&#39;&#34;)

        if &#34;std&#34; in srule.index:
            rule = RegressionRule()
        elif &#34;criterion&#34; in srule.index:
            rule = ClassificationRule()
        else:
            rule = Rule()
        rule_idx = copy(rule.__class__.rule_index)
        condition_index = {c: None for c in rule.__class__.condition_index}

        for rule_ind in srule.index:
            str_value = str(srule[rule_ind])
            if rule_ind in condition_index:
                condition_index[rule_ind] = ast.literal_eval(str_value)
            elif rule_ind in rule_idx:
                if rule_ind == &#34;activation&#34;:
                    setattr(rule, f&#34;_{rule_ind}&#34;, Activation(str_value))
                elif str_value == &#34;nan&#34;:
                    setattr(rule, f&#34;_{rule_ind}&#34;, np.nan)
                elif rule_ind == &#34;sign&#34;:
                    setattr(rule, f&#34;_{rule_ind}&#34;, str_value)
                else:
                    if rule_ind == &#34;prediction&#34;:  # Prediction can be a str in case of classification
                        try:
                            setattr(rule, f&#34;_{rule_ind}&#34;, ast.literal_eval(str_value))
                        except ValueError:
                            setattr(rule, f&#34;_{rule_ind}&#34;, str_value)
                    else:
                        setattr(rule, f&#34;_{rule_ind}&#34;, ast.literal_eval(str_value))
            else:
                continue

        rule._condition = HyperrectangleCondition(**condition_index)
        if hasattr(rule, rule.__class__.fitted_if_has) and getattr(rule, rule.__class__.fitted_if_has) is not None:
            rule._fitted = True
        return rule

    def calc_predictions(
        self, y: [np.ndarray, pd.Series], stacked_activations: Optional[pd.DataFrame] = None
    ) -&gt; Union[pd.Series, pd.DataFrame]:
        &#34;&#34;&#34;
        Will compute the prediction of each rule in the ruleset. Does NOT set anything in either the rules nor the
        ruleset.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
            The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
            np.ndarray or pd.Series.
        stacked_activations: Optional[pd.DataFrame)
            If specified, uses this activation instead of self.activation

        Returns
        -------
        Union[pd.Series, pd.DataFrame]
            Regression : A pd.Series with the rules as index and the values being the predictions\n
            Classification : A pd.DataFrame with rules as index and classes as columns, and class probabilities as
            values
        &#34;&#34;&#34;
        if stacked_activations is None:
            stacked_activations = self.stacked_activations
            if stacked_activations is None:
                raise ValueError(&#34;Stacked activation vectors are needed&#34;)

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
            if len(self) == 0:
                if self.rule_type is None:
                    return pd.Series(dtype=int)
                elif issubclass(self.rule_type, ClassificationRule):
                    return pd.DataFrame(dtype=int)
                elif issubclass(self.rule_type, RegressionRule):
                    return pd.Series(dtype=int)
                else:
                    raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

            if issubclass(self.rule_type, ClassificationRule):
                class_probabilities = functions.class_probabilities(stacked_activations, y)
                maxs = class_probabilities.max()
                return class_probabilities[class_probabilities == maxs].apply(
                    lambda x: x.dropna().sort_index().index[0]
                )
            elif issubclass(self.rule_type, RegressionRule):
                return functions.conditional_mean(stacked_activations, y)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_stds(self, y: [np.ndarray, pd.Series], stacked_activations: Optional[pd.DataFrame] = None) -&gt; pd.Series:
        &#34;&#34;&#34;
        Will compute the std of each rule in the ruleset. Does NOT set anything in either the rules nor the
        ruleset.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
          The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D np.ndarray
          or pd.Series.
        stacked_activations: Optional[pd.DataFrame]
            If specified, uses this activation instead of self.activation

        Returns
        -------
        pd.Series
            A pd.Series with the rules as index and the values being the std
        &#34;&#34;&#34;
        if not issubclass(self.rule_type, RegressionRule):
            raise TypeError(f&#34;&#39;std&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)

        if stacked_activations is None:
            stacked_activations = self.stacked_activations
            if stacked_activations is None:
                raise ValueError(&#34;Stacked activation vectors are needed&#34;)

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
            if len(self) == 0:
                if self._rule_type is None:
                    return pd.Series(dtype=int)
                elif issubclass(self.rule_type, RegressionRule):
                    return pd.Series(dtype=int)
                else:
                    raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

            if issubclass(self.rule_type, RegressionRule):
                return functions.conditional_std(stacked_activations, y)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_signs(self, predictions: Optional[pd.Series] = None) -&gt; pd.Series:
        &#34;&#34;&#34;
        Computes the sign of each rule in the ruleset.

        Rules predictions must have been set or be given to the method.
        &#34;&#34;&#34;
        if issubclass(self.rule_type, RegressionRule):
            if predictions is None:
                predictions = pd.Series({str(r.condition): r.prediction for r in self})
            return predictions.apply(lambda x: None if x is None else (&#34;-&#34; if x &lt; 0 else &#34;+&#34;))
        else:
            raise TypeError(f&#34;&#39;sign&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)

    def calc_zscores(
        self,
        y: np.ndarray,
        predictions: Optional[pd.Series] = None,
        nones: Optional[pd.Series] = None,
        horizon: int = 1,
    ) -&gt; pd.Series:
        if not issubclass(self.rule_type, RegressionRule):
            raise TypeError(f&#34;&#39;sign&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)
        if nones is None:
            nones = pd.Series({str(r.condition): r.nones for r in self})

        if predictions is None:
            predictions = self.calc_predictions(y=y)
            &#34;&#34;&#34;unique prediction of each rules in a pd.Series&#34;&#34;&#34;

        return calc_zscore_external(prediction=predictions, nones=nones, y=y, horizon=horizon)

    def calc_criterions(
        self,
        y: Union[np.ndarray, pd.Series],
        predictions: Optional[pd.Series] = None,
        stacked_activations: Optional[pd.DataFrame] = None,
        **kwargs,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;
        Will compute the criterion of each rule in the ruleset. Does NOT set anything in either the rules nor the
        ruleset.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
            The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
            np.ndarray or pd.Series.
        predictions: Optional[pd.Series]
            Prediction of each rules. If None, will call self.calc_predictions(y)
        stacked_activations: Optional[pd.DataFrame]
            If specified, uses those activations instead of self.stacked_activations
        kwargs

        Returns
        -------
        pd.Series
            Criterion values a set of rules (pd.Series)

        &#34;&#34;&#34;
        if stacked_activations is None:
            stacked_activations = self.stacked_activations
            if stacked_activations is None:
                raise ValueError(&#34;Stacked activation vectors are needed&#34;)

        if predictions is None:
            predictions = self.calc_predictions(y=y)
            &#34;&#34;&#34;unique prediction of each rules in a pd.Series&#34;&#34;&#34;

        if self._rule_type is None:
            return pd.Series(dtype=int)
        if issubclass(self.rule_type, ClassificationRule):
            return functions.calc_classification_criterion(stacked_activations, predictions, y, **kwargs)
        elif issubclass(self.rule_type, RegressionRule):
            return functions.calc_regression_criterion(
                stacked_activations.replace(0, np.nan) * predictions, y, **kwargs
            )
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_train_set_sizes(self, y: Union[np.ndarray, pd.Series]) -&gt; pd.Series:
        if isinstance(y, (pd.Series, pd.DataFrame)):
            s = len(y.index)
        else:
            s = len(y)
        return pd.Series({str(r.condition): s for r in self})

    def calc_test_set_sizes(self, y: Union[np.ndarray, pd.Series]) -&gt; pd.Series:
        if isinstance(y, (pd.Series, pd.DataFrame)):
            s = len(y.index)
        else:
            s = len(y)
        return pd.Series({str(r.condition): s for r in self})

    def predict(
        self,
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        weights: Optional[Union[pd.Series, str]] = None,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;Computes the prediction vector of an entier ruleset from its rules predictions and its activation vector.
        Predictions of rules must have been computed beforehand if &#39;xs&#39; is not specified.

        Parameters
        ----------
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
            If specified, uses those features to compute the ruleset&#39;s activation. Does not change the activation
            vectors nor the predictions of the ruleset&#39;s rules nor its own activation and stacked activations.
        weights: Optional[Union[pd.Series, str]]
            Optional weights. If is a pd.Series, expects the index to be the rules names. If is a str, a pd.Series
            will be constructed by fetching each rules&#39; attribute named after the given string
            (ex: it can be &#39;criterion&#39;)

        Returns
        -------
        pd.Series
            The prediction vector of the ruleset. Index are observations numbers, values are the predicted values when
            the ruleset predicts, else NaN.
        &#34;&#34;&#34;
        if len(self) == 0:
            return pd.Series(dtype=int)
        if self._rule_type is None:
            return pd.Series(dtype=int)

        stacked = self.__class__.STACKED_FIT and self.stacked_activations is not None

        stacked_activations = None
        if xs is not None and stacked:
            stacked_activations = self.evaluate_stacked_activations(xs=xs)
        if stacked:
            return self._calc_prediction_stacked(weights=weights, stacked_activations=stacked_activations)
        else:
            return self._calc_prediction_unstacked(weights=weights, xs=xs)

    def _calc_prediction_stacked(
        self, weights: Optional[Union[pd.Series, str]] = None, stacked_activations: Optional[pd.DataFrame] = None
    ) -&gt; Union[None, pd.Series]:
        predictions = pd.Series({str(r.condition): getattr(r, &#34;prediction&#34;) for r in self})

        if stacked_activations is None:
            stacked_activations = self.stacked_activations
        if stacked_activations is None:
            return None

        if isinstance(self[0].prediction, str):
            prediction_vectors = stacked_activations.replace(0, np.nan).replace(1.0, &#34;&#34;) + predictions
        else:
            prediction_vectors = stacked_activations.replace(0, np.nan) * predictions
        if prediction_vectors.empty:
            return prediction_vectors
        if weights is not None:
            if isinstance(weights, str):
                weights = pd.Series({str(r.condition): getattr(r, weights) for r in self})
            weights = stacked_activations.replace(0, np.nan) * weights
            if issubclass(self.rule_type, RegressionRule):
                return calc_ruleset_prediction_weighted_regressor_stacked(
                    prediction_vectors=prediction_vectors, weights=weights
                )
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_weighted_classificator_stacked(
                    prediction_vectors=prediction_vectors, weights=weights
                )
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)
        else:
            if issubclass(self.rule_type, RegressionRule):
                return calc_ruleset_prediction_equally_weighted_regressor_stacked(prediction_vectors=prediction_vectors)
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_equally_weighted_classificator_stacked(
                    prediction_vectors=prediction_vectors
                )
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def _calc_prediction_unstacked(
        self,
        weights: Optional[Union[pd.Series, str]] = None,
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
    ) -&gt; pd.Series:

        if weights is not None:
            if isinstance(weights, str):
                weights = pd.Series({str(r.condition): getattr(r, weights) for r in self})
            if issubclass(self.rule_type, RegressionRule):

                return calc_ruleset_prediction_weighted_regressor_unstacked(rules=self.rules, weights=weights, xs=xs)
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_weighted_classificator_unstacked(
                    rules=self.rules, weights=weights, xs=xs
                )
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)
        else:
            if issubclass(self.rule_type, RegressionRule):
                return calc_ruleset_prediction_equally_weighted_regressor_unstacked(rules=self.rules, xs=xs)
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_equally_weighted_classificator_unstacked(rules=self.rules, xs=xs)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_criterion(
        self,
        y: Union[np.ndarray, pd.Series],
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        weights: Optional[Union[pd.Series, str]] = None,
        predictions: Optional[pd.Series] = None,
        **kwargs,
    ):
        &#34;&#34;&#34;Computes the criterion of an entier ruleset. Predictions of rules must have been computed beforehand.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Sets self.criterion so does not return anything

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
            The targets on which to evaluate the ruleset criterions. Must be a 1-D np.ndarray or pd.Series.
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
            If specified, uses those features to compute the ruleset&#39;s activation. Does not change the activation
            vectors nor the predictions of its rules. If specified and if self.stack_activation is True, will overwrite
            the ruleset&#39;s stacked activation vectors. Else, only ruleset&#39;s activation is overwritten.
        weights: Optional[Union[pd.Series, str]]
            Optional weights. If is a pd.Series, expected the index to be the rules names. If is a str, a pd.Series
            will be constructed by fetching each rules&#39; attribute named after the given string
            (ex: it can be &#39;criterion&#39;).
            Useless if predictions is specified.
        predictions: Optional[pd.Series]
            The vector of predictions of the ruleset. If not specified, is computed using self.calc_prediction
        kwargs
        &#34;&#34;&#34;
        if len(self) == 0:
            return np.nan
        if self._rule_type is None:
            return np.nan
        if predictions is None:
            predictions = self.predict(xs=xs, weights=weights)
        if len(predictions) == 0:
            self.criterion = np.nan
            return
        if issubclass(self.rule_type, ClassificationRule):
            if xs is not None:
                activation = self.evaluate_self_activation(xs=xs).raw
            else:
                if self._activation is None or self._activation.length == 0:
                    self.compute_self_activation()
                activation = self.activation
            self.criterion = functions.calc_classification_criterion(activation, predictions, y, **kwargs)
        elif issubclass(self.rule_type, RegressionRule):
            # noinspection PyTypeChecker
            self.criterion = functions.calc_regression_criterion(predictions, y, **kwargs)
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_test_set_size(self, y: Union[np.ndarray, pd.Series]):
        if isinstance(y, (pd.Series, pd.DataFrame)):
            self.test_set_size = len(y.index)
        else:
            self.test_set_size = len(y)

    def calc_train_set_size(self, y: Union[np.ndarray, pd.Series]):
        if isinstance(y, (pd.Series, pd.DataFrame)):
            self.train_set_size = len(y.index)
        else:
            self.train_set_size = len(y)


def traverse(o, tree_types=(list, tuple, RuleSet)):
    &#34;&#34;&#34;Yields each elementary elements from nested list or tuple

    Example
    -------
    &gt;&gt;&gt; list(traverse([[[1, 2], 3,], [4, 5]]))
    [1, 2, 3, 4, 5]
    &#34;&#34;&#34;
    if isinstance(o, tree_types):
        for value in o:
            for subvalue in traverse(value, tree_types):
                yield subvalue
    else:
        yield o</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ruleskit.ruleset.traverse"><code class="name flex">
<span>def <span class="ident">traverse</span></span>(<span>o, tree_types=(&lt;class &#x27;list&#x27;&gt;, &lt;class &#x27;tuple&#x27;&gt;, &lt;class &#x27;ruleskit.ruleset.RuleSet&#x27;&gt;))</span>
</code></dt>
<dd>
<div class="desc"><p>Yields each elementary elements from nested list or tuple</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; list(traverse([[[1, 2], 3,], [4, 5]]))
[1, 2, 3, 4, 5]
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def traverse(o, tree_types=(list, tuple, RuleSet)):
    &#34;&#34;&#34;Yields each elementary elements from nested list or tuple

    Example
    -------
    &gt;&gt;&gt; list(traverse([[[1, 2], 3,], [4, 5]]))
    [1, 2, 3, 4, 5]
    &#34;&#34;&#34;
    if isinstance(o, tree_types):
        for value in o:
            for subvalue in traverse(value, tree_types):
                yield subvalue
    else:
        yield o</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ruleskit.ruleset.RuleSet"><code class="flex name class">
<span>class <span class="ident">RuleSet</span></span>
<span>(</span><span>rules_list: Optional[List[<a title="ruleskit.rule.Rule" href="rule.html#ruleskit.rule.Rule">Rule</a>]] = None, compute_activation: bool = True, stack_activation: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>A set of rules</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>rules_list</code></strong> :&ensp;<code>Union[List[Rule], None]</code></dt>
<dd>The list of rules to start with. Can be None, since a RuleSet can be filled after its creation.</dd>
<dt><strong><code>compute_activation</code></strong> :&ensp;<code>bool</code></dt>
<dd>The activation of the RuleSet is the logical OR of the activation of all its rules. It is only computed
if compute_activation is True. (default value = True)</dd>
<dt><strong><code>stack_activation</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, the RuleSet will keep in memory 2-D np.ndarray containing the activations of all its rules. This
can take a lot of memory, but can save time if you apply numpy methods on this stacked vector instead of on
each rule separately. (default value = False)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RuleSet(ABC):

    &#34;&#34;&#34;A set of rules&#34;&#34;&#34;

    NLINES = 5  # half how many rules to show in str(self)
    CHECK_DUPLICATED = False
    STACKED_FIT = False
    all_features_indexes = {}
    attributes_from_train_set = {ClassificationRule: [&#34;train_set_size&#34;], RegressionRule: [&#34;train_set_size&#34;]}
    attributes_from_test_set = {
        ClassificationRule: [&#34;criterion&#34;, &#34;test_set_size&#34;], RegressionRule: [&#34;criterion&#34;, &#34;test_set_size&#34;]
    }

    @staticmethod
    def check_duplicated_rules(rules, name_or_index: str = &#34;index&#34;):
        if name_or_index == &#34;index&#34;:
            str_rules = [str(r.features_indexes) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in rules]
        else:
            str_rules = [str(r.features_names) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in rules]
        if len(set(str_rules)) &lt; len(str_rules):
            duplicated = {}
            for r in str_rules:
                if r not in duplicated:
                    duplicated[r] = 0
                duplicated[r] += 1
            duplicated = [
                f&#34;{r}: {duplicated[r]} (positions {[i for i, x in enumerate(str_rules) if x == r]})\n&#34;
                f&#34;   underlying rules : {[str(rules[i]) for i in [i for i, x in enumerate(str_rules) if x == r]]}&#34;
                for r in duplicated
                if duplicated[r] &gt; 1
            ]
            s = &#34;\n -&#34;.join(duplicated)
            raise ValueError(f&#34;There are {len(duplicated)} duplicated rules in your ruleset !\n {s}&#34;)

    def __init__(
        self,
        rules_list: Union[List[Rule], None] = None,
        compute_activation: bool = True,
        stack_activation: bool = False,
    ):
        &#34;&#34;&#34;

        Parameters
        ----------
        rules_list: Union[List[Rule], None]
            The list of rules to start with. Can be None, since a RuleSet can be filled after its creation.
        compute_activation: bool
            The activation of the RuleSet is the logical OR of the activation of all its rules. It is only computed
            if compute_activation is True. (default value = True)
        stack_activation: bool
            If True, the RuleSet will keep in memory 2-D np.ndarray containing the activations of all its rules. This
            can take a lot of memory, but can save time if you apply numpy methods on this stacked vector instead of on
            each rule separately. (default value = False)
        &#34;&#34;&#34;
        self._rules: List[Rule] = []
        self.features_names: List[str] = []
        self.features_indexes: List[int] = []
        self._activation: Optional[Activation] = None
        self._coverage: Optional[float] = None  # in case Activation is not available
        self.criterion: Optional[float] = None
        self.train_set_size: Optional[int] = None
        self.test_set_size: Optional[int] = None
        &#34;&#34;&#34;Set by self.eval&#34;&#34;&#34;
        self.stacked_activations: Optional[pd.DataFrame] = None
        self.stack_activation: bool = stack_activation
        self._rule_type = None
        self._compute_activation = True  # Should NOT be equal to given compute_activation argument, but always True.
        if rules_list is not None:
            names_available = all([hasattr(r.condition, &#34;features_names&#34;) for r in self])
            for rule in rules_list:
                if not isinstance(rule, Rule) and rule is not None:
                    raise TypeError(f&#34;Some rules in given iterable were not of type &#39;Rule&#39; but of type {type(rule)}&#34;)
                if rule is not None:
                    self.append(rule, update_activation=False)
            if compute_activation:
                self.compute_self_activation()
            if self.stack_activation:
                self.compute_stacked_activation()
            if names_available:
                self.features_names = list(set(itertools.chain(*[rule.features_names for rule in self])))
            self.set_features_indexes()
        if self.__class__.CHECK_DUPLICATED:
            self.check_duplicated_rules(self.rules, name_or_index=&#34;name&#34; if len(self.features_names) &gt; 0 else &#34;index&#34;)

    # noinspection PyProtectedMember,PyTypeChecker
    def __iadd__(self, other: Union[&#34;RuleSet&#34;, Rule]):
        &#34;&#34;&#34;Appends a rule or each rules of another RuleSet to self and updates activation vector and stacked activations
        if needed. Also updates features_indexes, and features_names if possible.&#34;&#34;&#34;
        if isinstance(other, Rule):
            self._rules.append(other)
        else:
            self._rules += other._rules
        self.features_indexes = list(set(self.features_indexes + other.features_indexes))
        if hasattr(other, &#34;features_names&#34;):
            self.features_names = list(set(self.features_names + other.features_names))
        if self._compute_activation:
            self._update_activation(other)
        if self.stack_activation:
            self._update_stacked_activation(other)
        return self

    def __add__(self, other: Union[&#34;RuleSet&#34;, Rule]):
        &#34;&#34;&#34;Returns the RuleSet resulting in appendind a rule or each rules of another RuleSet to self.&#34;&#34;&#34;
        stack_activation = self.stack_activation
        if isinstance(other, Rule):
            rules = self.rules + [other]
        else:
            stack_activation &amp;= other.stack_activation
            rules = list(set(self.rules + other.rules))
        return self.__class__(rules, compute_activation=self._compute_activation, stack_activation=stack_activation)

    def __getattr__(self, item):
        &#34;&#34;&#34;If item is not found in self, try to fetch it from its activation.&#34;&#34;&#34;
        if item == &#34;_activation&#34;:
            raise AttributeError(f&#34;&#39;RuleSet&#39; object has no attribute &#39;{item}&#39;&#34;)

        if self._activation is not None and hasattr(self._activation, item):
            return getattr(self._activation, item)
        raise AttributeError(f&#34;&#39;RuleSet&#39; object has no attribute &#39;{item}&#39;&#34;)

    def __len__(self):
        &#34;&#34;&#34;The length of a RuleSet its the number of rules stored in it.&#34;&#34;&#34;
        return len(self.rules)

    def __eq__(self, other: &#34;RuleSet&#34;):
        return set(self.rules) == set(other.rules)

    def __iter__(self):
        if hasattr(self, &#34;_rules&#34;):
            return self.rules.__iter__()
        else:
            return [].__iter__()

    def __getitem__(self, key):
        if isinstance(key, slice):
            indices = range(*key.indices(len(self.rules)))
            return self.__class__([self.rules[i] for i in indices])
        return self.rules.__getitem__(key)

    def __str__(self):
        if len(self) &lt; 2 * self.__class__.NLINES:
            return &#34;\n&#34;.join([str(self[i]) for i in range(len(self))])
        else:
            return &#34;\n&#34;.join(
                [str(self[i]) for i in range(self.__class__.NLINES)]
                + [&#34;...&#34;]
                + [str(self[i]) for i in range(len(self) - self.__class__.NLINES, len(self))]
            )

    def __hash__(self) -&gt; hash:
        return hash(frozenset(self.to_hash))

    # noinspection PyProtectedMember
    def __contains__(self, other: Rule) -&gt; bool:
        &#34;&#34;&#34;A RuleSet contains another Rule if the two rule&#39;s conditions and predictions are the same&#34;&#34;&#34;
        name_or_index = &#34;name&#34; if len(self.features_names) &gt; 0 else &#34;index&#34;

        if name_or_index == &#34;index&#34;:
            str_rules = [str(r.features_indexes) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in self]
            str_rule = str(other.features_indexes) + str(other.bmins) + str(other.bmaxs) + str(other.prediction)
        else:
            str_rules = [str(r.features_names) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in self]
            str_rule = str(other.features_names) + str(other.bmins) + str(other.bmaxs) + str(other.prediction)

        return str_rule in str_rules

    @property
    def rule_type(self) -&gt; type:
        if self._rule_type is None:
            raise ValueError(&#34;Ruleset&#39;s rule type is not set !&#34;)
        return self._rule_type

    @rule_type.setter
    def rule_type(self, rule_type: type):
        if not issubclass(rule_type, (ClassificationRule, RegressionRule, Rule)):
            raise TypeError(
                &#34;Ruleset&#39;s rule type must be a subclass of ruleskit.RegressionRule or ruleskit.ClassificationRule, not&#34;
                f&#34; {rule_type}&#34;
            )
        self._rule_type = rule_type

    @property
    def rules(self) -&gt; List[Rule]:
        return self._rules

    @rules.setter
    def rules(self, rules: Union[List[Rule], None]):
        ruleset = RuleSet(rules, stack_activation=self.stack_activation)
        self._rules = ruleset._rules
        self.features_names = ruleset.features_names
        self.features_indexes = ruleset.features_indexes
        self.stacked_activations = ruleset.stacked_activations
        self._activation = ruleset._activation

    @property
    def to_hash(self) -&gt; Tuple[str]:
        if len(self) == 0:
            return &#34;rs&#34;,
        to_hash = (&#34;rs&#34;,)
        for r in self:
            rule_hash = r.to_hash[1:]
            to_hash += rule_hash
        return to_hash

    @property
    def activation_available(self) -&gt; bool:
        &#34;&#34;&#34;Returns True if the RuleSet has an activation vector, and if this Activation&#39;s object data is available.&#34;&#34;&#34;
        if self._activation is None or self._activation.length == 0:
            return False
        if self._activation.data_format == &#34;file&#34;:
            return self._activation.data.is_file()
        else:
            return self._activation.data is not None

    @property
    def stacked_activations_available(self) -&gt; bool:
        &#34;&#34;&#34;Returns True is the RuleSet has its rules&#39; stacked activations.&#34;&#34;&#34;
        if self.stack_activation is None or self._activation.length == 0:
            return False
        return True

    @property
    def activation(self) -&gt; Union[None, np.ndarray]:
        &#34;&#34;&#34;Returns the Activation vector&#39;s data in a form of a 1-D np.ndarray, or None if not available.

        Returns:
        --------
        Union[None, np.ndarray]
            of the form [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, ...]
        &#34;&#34;&#34;
        if self._activation:
            return self._activation.raw
        return None

    @property
    def ruleset_coverage(self) -&gt; float:
        &#34;&#34;&#34;Coverage is the fraction of points equal to 1 in the activation vector&#34;&#34;&#34;
        if not self.activation_available:
            return self._coverage
        else:
            return self._activation.coverage

    # noinspection PyProtectedMember,PyTypeChecker
    def _update_activation(self, other: Union[Rule, &#34;RuleSet&#34;]):
        &#34;&#34;&#34;Updates the activation vector of the RuleSet with the activation vector of a new Rule or RuleSet.&#34;&#34;&#34;
        if other.activation_available:
            if self._activation is None or self._activation.length == 0:
                self._activation = Activation(other.activation, to_file=Rule.LOCAL_ACTIVATION)
            else:
                self._activation = self._activation | other._activation

    # noinspection PyProtectedMember,PyTypeChecker
    def _update_stacked_activation(self, other: Union[Rule, &#34;RuleSet&#34;]):
        &#34;&#34;&#34;Updates the stacked activation vectors of the RuleSet with the activation vector of a new Rule or
        the stacked activation vectors of another RuleSet.&#34;&#34;&#34;
        if other.activation_available:

            if self.stacked_activations is None:
                if isinstance(other, Rule):
                    self.stacked_activations = pd.DataFrame(
                        data=np.array(other.activation).T, columns=[str(other.condition)]
                    )
                else:
                    self.stacked_activations = other.stacked_activations
            else:
                if isinstance(other, Rule):
                    self.stacked_activations[str(other.condition)] = other.activation
                else:
                    self.stacked_activations = pd.concat([self.stacked_activations, other.stacked_activations], axis=1)

    def set_features_indexes(self):
        if len(self.__class__.all_features_indexes) &gt; 0:
            self.features_indexes = [self.__class__.all_features_indexes[f] for f in self.features_names]
            for r in self._rules:
                # noinspection PyProtectedMember
                r._condition._features_indexes = [self.__class__.all_features_indexes[f] for f in r.features_names]
        else:
            list(set(itertools.chain(*[rule.features_indexes for rule in self])))

    # noinspection PyProtectedMember
    def fit(
        self,
        y: Union[np.ndarray, pd.Series],
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        force_if_not_good: bool = False,
        **kwargs,
    ) -&gt; List[Rule]:
        &#34;&#34;&#34;Fits the ruleset on y and xs to produce the rules&#39; activation vectors and attributes relevant to train set.

        Parameters
        ----------
        y: Union[np.ndarray, pd.Series]
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
        force_if_not_good: bool
        kwargs

        Returns
        -------
        List[Rule]
            List of rules that were excluded from the ruleset after fitting because they were &#39;bad&#39;
        &#34;&#34;&#34;
        if issubclass(self.rule_type, ClassificationRule):
            type_to_use = ClassificationRule
        elif issubclass(self.rule_type, RegressionRule):
            type_to_use = RegressionRule
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

        if &#34;method&#34; in kwargs:
            raise IndexError(&#34;Key &#39;method&#39; can not be given to &#39;fit&#39;&#34;)

        def launch_method(method, **kw):
            expected_args = list(inspect.signature(method).parameters)
            if &#34;kwargs&#34; not in expected_args:
                kw = {item: kw[item] for item in kw if item in expected_args}
            return method(**kw)

        if xs is not None and len(xs) == 0:
            logger.warning(&#34;Given xs is empty&#34;)
            return []

        if len(self) == 0:
            logger.debug(&#34;Ruleset is empty. Nothing to fit.&#34;)
            return []

        if all([r._fitted for r in self]) and xs is None:
            return []

        if self.__class__.STACKED_FIT:

            clean_activation = False
            # Activation must always be computed from train set
            if xs is not None:
                clean_activation = not self.stack_activation
                self.stack_activation = True
                self.calc_activation(xs)
                self.stack_activation = not clean_activation
            elif self.stacked_activations is None:
                clean_activation = not self.stack_activation
                self.stack_activation = True
                self.compute_stacked_activation()
                self.stack_activation = not clean_activation

            if isinstance(y, np.ndarray):
                # noinspection PyUnresolvedReferences
                if not len(self.stacked_activations.index) == y.shape[0]:
                    raise IndexError(
                        &#34;Stacked activation and y have different number of rows. Use pd.Series for y to&#34;
                        &#34; reindex stacked activations automatically.&#34;
                    )
            else:
                self.stacked_activations.index = y.index

            computed_attrs = {}
            # noinspection PyUnresolvedReferences
            for attr in self.rule_type.attributes_from_train_set:
                if attr == &#34;activation&#34;:
                    raise ValueError(&#34;&#39;activation&#39; can not be specified in &#39;attributes_from_train_set&#39;&#34;)
                computed_attrs[f&#34;{attr}s&#34;] = launch_method(
                    getattr(self, f&#34;calc_{attr}s&#34;), y=y, xs=xs, **computed_attrs, **kwargs
                )
            to_drop = []

            if clean_activation:
                self.del_stacked_activations()
            else:
                if isinstance(y, np.ndarray):
                    self.stacked_activations.index = pd.RangeIndex(y.shape[0])
                else:
                    self.stacked_activations.index = pd.RangeIndex(len(y.index))

            for ir in range(len(self)):
                self._rules[ir]._fitted = True
                for attr in computed_attrs:
                    setattr(self._rules[ir], f&#34;_{attr[:-1]}&#34;, computed_attrs[attr].iloc[ir])
                    if self._rules[ir].good:
                        self._rules[ir].check_thresholds(attr[:-1])
                    if not self._rules[ir].good:
                        to_drop.append(self._rules[ir])
                # To check attributes that are set along side others, like coverage
                if self._rules[ir].good:
                    self._rules[ir].check_thresholds()
        else:
            [r.fit(xs=xs, y=y, force_if_not_good=force_if_not_good, **kwargs) for r in self]
            to_drop = [r for r in self if not r.good]

        if len(to_drop) &gt; 0:
            rules = [r for r in self.rules if r not in to_drop]
            self._rules = []
            if self._activation is not None:
                self._activation.clear()
            self.del_stacked_activations()
            for r in rules:
                self.append(r, update_activation=False)

            # Recompute activation now that bad rules have been droped
            self._activation = None
            self.compute_self_activation()
            if self.stack_activation:
                self.stacked_activations = None
                self.compute_stacked_activation()
        # If not bad rules were dropped and stacked fit was not used, still compute self.activation since it has not
        # been done  (needed to set self.coverage), but not stacked (useless)
        elif not self.__class__.STACKED_FIT:
            if self._activation is None or self._activation.length == 0 or xs is not None:
                self._activation = None
                self.compute_self_activation()
            if self.stack_activation and (self.stacked_activations is None or xs is not None):
                self.stacked_activations = None
                self.compute_stacked_activation()

        for attr in self.__class__.attributes_from_train_set[type_to_use]:
            launch_method(
                getattr(self, f&#34;calc_{attr}&#34;),
                y=y,
                xs=xs,
                **kwargs,
            )

        return to_drop

    # noinspection PyProtectedMember
    def eval(
        self,
        y: Union[np.ndarray, pd.Series],
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        keep_new_activations: bool = False,
        weights: Optional[Union[pd.Series, str]] = None,
        force_if_not_good: bool = False,
        **kwargs,
    ) -&gt; List[Rule]:
        &#34;&#34;&#34;Evaluate the ruleset on y and xs to produce the rules&#39; attributes relevant to the test set. Will recompute
        the ruleset&#39;s stacked activation vector if using stakced fit.

        Parameters
        ----------
        y: Union[np.ndarray, pd.Series]
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
        keep_new_activations: bool
            If True, activation vectgor and stacked activation vectors will be kept as ruleset&#39;s attribute and replace
            the ones computed using the train set, if any. Will also change the activation vectors of the rules.
        weights: Optional[Union[pd.Series, str]]
            Optional weights for calc_critetion. If is a pd.Series, expects the index to be the rules names.
            If is a str, a pd.Series will be constructed by fetching each rules&#39; attribute named after the given string
            (ex: it can be &#39;criterion&#39;)
        force_if_not_good: bool
            If the rule was seen as &#34;bad&#34;, eval will not trigger unless this boolean is True (Default value = False)
        kwargs


        Returns
        -------
        List[Rule]
            List of rules that were excluded from the ruleset after fitting because they were &#39;bad&#39;
        &#34;&#34;&#34;
        if issubclass(self.rule_type, ClassificationRule):
            type_to_use = ClassificationRule
        elif issubclass(self.rule_type, RegressionRule):
            type_to_use = RegressionRule
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

        if &#34;method&#34; in kwargs:
            raise IndexError(&#34;Key &#39;method&#39; can not be given to &#39;eval&#39;&#34;)

        def launch_method(method, **kw):
            expected_args = list(inspect.signature(method).parameters)
            if &#34;kwargs&#34; not in expected_args:
                kw = {item: kw[item] for item in kw if item in expected_args}
            return method(**kw)

        if xs is not None and len(xs) == 0:
            logger.warning(&#34;Given xs is empty&#34;)
            return []

        if len(self) == 0:
            logger.debug(&#34;Ruleset is empty. Nothing to fit.&#34;)
            return []

        if not all([r._fitted for r in self]):
            if xs is None:
                raise ValueError(
                    &#34;Not all rules of the ruleset were fitted. Please do so before calling ruleset.eval or provide xs.&#34;
                )
            else:
                keep_new_activations = True

        if self.__class__.STACKED_FIT:
            clean_activation = False

            # If test set is given, compute the activation used to evaluate test relative attributes.
            # Not the same as self.stacked_activations, computed from the train set.
            # Else, we evaluate on the train set, so we use self.stacked_actviation
            nones = None
            if xs is not None:
                if keep_new_activations:
                    clean_activation = not self.stack_activation
                    self.stack_activation = True
                    self.calc_activation(xs=xs)  # Will reset rules&#39; activation vectors too
                    self.stack_activation = not clean_activation
                    stacked_activations = self.stacked_activations
                    activation = self._activation
                    # noinspection PyUnresolvedReferences
                    if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                        nones = pd.Series({str(r.condition): r.nones for r in self})
                else:
                    stacked_activations = self.evaluate_stacked_activations(xs)
                    # noinspection PyUnresolvedReferences
                    if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                        activation, nones = self.evaluate_self_activation(xs, return_nones=True)
                    else:
                        activation = self.evaluate_self_activation(xs)
            else:
                # If self.stacked_activations is None, compute it from the rules&#39; activations. They must be available.
                if self.stacked_activations is None:
                    # Else, will compute the stacked activation from the current rules activations
                    clean_activation = not self.stack_activation
                    self.stack_activation = True
                    self.compute_stacked_activation()
                    self.compute_self_activation()
                    if self.stacked_activations is None:
                        raise ValueError(&#34;Rules activations must have been computed previously.&#34;)
                    self.stack_activation = not clean_activation
                stacked_activations = self.stacked_activations
                activation = self._activation
                # noinspection PyUnresolvedReferences
                if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                    nones = pd.Series({str(r.condition): r.nones for r in self})

            if isinstance(y, np.ndarray):
                if not len(stacked_activations.index) == y.shape[0]:
                    raise IndexError(&#34;Stacked activation and y have different number of rows.&#34;)
            else:
                if not len(stacked_activations.index) == len(y.index):
                    raise IndexError(&#34;Stacked activation and y have different number of rows.&#34;)
                stacked_activations.index = y.index

            # noinspection PyUnresolvedReferences
            if &#34;prediction&#34; in self.rule_type.attributes_from_train_set:
                # Do NOT recompute prediction from test set : it does not make sense !
                predictions = pd.Series({str(r.condition): r.prediction for r in self})
            else:
                predictions = None
            computed_attrs = {}

            # noinspection PyUnresolvedReferences
            for attr in self.rule_type.attributes_from_test_set:
                if attr == &#34;activation&#34;:
                    raise ValueError(&#34;&#39;activation&#39; can not be specified in &#39;attributes_from_train_set&#39;&#34;)
                computed_attrs[f&#34;{attr}s&#34;] = launch_method(
                    getattr(self, f&#34;calc_{attr}s&#34;),
                    y=y,
                    xs=xs,
                    stacked_activations=stacked_activations,
                    activation=activation,
                    nones=nones,
                    predictions=predictions,
                    **computed_attrs,
                    **kwargs,
                )

            to_drop = []

            if clean_activation:
                self.del_stacked_activations()
            else:
                if isinstance(y, np.ndarray):
                    stacked_activations.index = pd.RangeIndex(y.shape[0])
                else:
                    stacked_activations.index = pd.RangeIndex(len(y.index))

            for ir in range(len(self)):
                self._rules[ir]._evaluated = True
                for attr in computed_attrs:
                    setattr(self._rules[ir], f&#34;_{attr[:-1]}&#34;, computed_attrs[attr].iloc[ir])
                    if self._rules[ir].good:
                        self._rules[ir].check_thresholds(attr[:-1])
                    if not self._rules[ir].good:
                        to_drop.append(self._rules[ir])
                if self._rules[ir].good:
                    self._rules[ir].check_thresholds()
        else:
            [
                r.eval(
                    xs=xs, y=y, recompute_activation=keep_new_activations,
                    force_if_not_good=force_if_not_good, **kwargs
                ) for r in self
            ]
            to_drop = [r for r in self if not r.good]

        if len(to_drop) &gt; 0:
            rules = [r for r in self.rules if r not in to_drop]
            self._rules = []
            if self._activation is not None:
                self._activation.clear()
            self.del_stacked_activations()
            for r in rules:
                self.append(r, update_activation=False)

            # Recompute activation now that bad rules have been droped
            if self._activation is None or self._activation.length == 0 or (xs is not None and keep_new_activations):
                self._activation = None
                self.compute_self_activation()
            if self.stack_activation and (
                self.stacked_activations is None or (xs is not None and keep_new_activations)
            ):
                self.stacked_activations = None
                self.compute_stacked_activation()
        # If not bad rules were dropped and stacked fit was not used, still compute self.activation since it has not
        # been done
        elif not self.__class__.STACKED_FIT:
            if self._activation is None or self._activation.length == 0 or (xs is not None and keep_new_activations):
                self._activation = None
                self.compute_self_activation()
            if self.stack_activation and (self._activation is None or (xs is not None and keep_new_activations)):
                self.stacked_activations = None
                self.compute_stacked_activation()

        for attr in self.__class__.attributes_from_test_set[type_to_use]:
            launch_method(
                getattr(self, f&#34;calc_{attr}&#34;),
                y=y,
                xs=xs if not keep_new_activations else None,
                weights=weights,
                **kwargs,
            )

        return to_drop

    def append(self, rule: Rule, update_activation: bool = True):
        &#34;&#34;&#34;Appends a new rule to self. The updates of activation vector and the stacked activation vectors can be
        blocked by specifying update_activation=False. Otherwise, will use self.stack_activation to determine if the
        updates should be done or not.&#34;&#34;&#34;
        if not isinstance(rule, Rule):
            raise TypeError(f&#34;RuleSet&#39;s append method expects a Rule object, got {type(rule)}&#34;)
        if self._rule_type is None:
            self.rule_type = type(rule)
        else:
            if not isinstance(rule, self.rule_type):
                raise TypeError(
                    f&#34;Ruleset previously had rules of type {self.rule_type}, so can not add rule of type {type(rule)}&#34;
                )
        stack_activation = self.stack_activation
        if not update_activation:
            self._compute_activation = False
            self.stack_activation = False
        self.__iadd__(rule)
        self._compute_activation = True
        self.stack_activation = stack_activation

    def sort(self, criterion: str = None, reverse: bool = False):
        &#34;&#34;&#34;Sorts the RuleSet.

        * If criterion is not speficied:
            Will sort the rules according to :
                1. The number of features they talk about
                2. For a same number of features (sorted in alphabetical order, or index if names are not available,
                    optionally reversed), the bmins and bmaxs of the rules
        * If criterion is specified, it must be an float or interger attribute of rule, condition or activation. Then
            sorts according to this criterion, optionally reversed.
        &#34;&#34;&#34;
        if len(self) == 0:
            return

        if criterion is None or criterion == &#34;&#34;:
            if not (hasattr(self[0].condition, &#34;bmins&#34;) and hasattr(self[0].condition, &#34;bmaxs&#34;)):
                return
            # The set of all the features the RuleSet talks about
            which = &#34;index&#34;
            if len(self.features_names) &gt; 0:
                which = &#34;name&#34;
                fnames_or_indexes = list(set([str(r.features_names) for r in self]))
            else:
                fnames_or_indexes = list(set([str(r.features_indexes) for r in self]))
            dict_names = {}
            lmax = 1
            for f in fnames_or_indexes:
                l_ = len(ast.literal_eval(f))
                if l_ &gt; lmax:
                    lmax = l_
                if l_ not in dict_names:
                    dict_names[l_] = []
                dict_names[l_].append(f)
            for l_ in dict_names:
                dict_names[l_].sort(reverse=reverse)
            fnames_or_indexes = []
            for l_ in range(1, lmax + 1):
                if l_ in dict_names:
                    fnames_or_indexes += dict_names[l_]

            rules_by_fnames = OrderedDict({f: [] for f in fnames_or_indexes})
            for rule in self:
                if which == &#34;name&#34;:
                    v = str(rule.features_names)
                else:
                    v = str(rule.features_indexes)
                rules_by_fnames[v].append(rule)
            rules_by_fnames = {
                n: sorted(rules_by_fnames[n], key=lambda x: x.condition.bmins + x.condition.bmaxs)
                for n in rules_by_fnames
            }
            self._rules = []
            for n in rules_by_fnames:
                self._rules += rules_by_fnames[n]
        elif hasattr(self[0], criterion):
            self._rules = sorted(self, key=lambda x: getattr(x, criterion), reverse=reverse)
        else:
            raise ValueError(f&#34;Can not sort RuleSet according to criterion {criterion}&#34;)
        if self.stack_activation:
            self.stacked_activations = self.stacked_activations[[str(r.condition) for r in self]]

    # noinspection PyProtectedMember
    def evaluate_self_activation(
            self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None, return_nones: bool = False
    ):
        &#34;&#34;&#34;Computes the activation vector of self from its rules, using time-efficient Activation.multi_logical_or.&#34;&#34;&#34;
        if len(self) == 0:
            act = Activation(np.array([]))
            if return_nones is True:
                return act, pd.Series(dtype=int)
            return act
        if xs is not None:
            activations = [r.evaluate_activation(xs) for r in self]
            activations_available = True
        else:
            activations = [r._activation for r in self]
            activations_available = all([r.activation_available for r in self])
        if activations_available:
            if len(self) == 1:
                act = Activation(activations[0].raw, optimize=activations[0].optimize, to_file=activations[0].to_file)
                if return_nones is True:
                    return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
                return act
            try:
                act = Activation.multi_logical_or(activations)
                if return_nones is True:
                    return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
                return act
            except (MemoryError, np.core._exceptions._ArrayMemoryError):
                act = Activation(activations[0], optimize=activations[0].optimize, to_file=activations[0].to_file)
                for a in activations:
                    act = act or a
                if return_nones is True:
                    return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
                return act

    def compute_self_activation(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
        &#34;&#34;&#34;Computes the activation vector of self from its rules. If xs is specified, uses it to remake the
        rules&#39; activation vectors, but do not set them as the &#39;activation&#39; attributes of the rules&#34;&#34;&#34;
        self._activation = self.evaluate_self_activation(xs=xs)

    def evaluate_stacked_activations(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
        if len(self) == 0:
            return pd.DataFrame(dtype=int)
        if xs is not None:
            return pd.DataFrame({str(r.condition): r.evaluate_activation(xs).raw for r in self})
        activations_available = all([r.activation_available for r in self])
        if activations_available:
            # noinspection PyProtectedMember
            return pd.DataFrame({str(r.condition): r.activation for r in self})

    def compute_stacked_activation(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
        &#34;&#34;&#34;Computes the stacked activation vectors of self from its rules. If xs is specified, uses it to remake the
        rules&#39; activation vectors, but do not set them as the &#39;activation&#39; attributes of the rules&#34;&#34;&#34;
        self.stacked_activations = self.evaluate_stacked_activations(xs=xs)

    def del_activations(self):
        &#34;&#34;&#34;Deletes the data, but not the relevent attributes, of the activation vector or each rules in self.&#34;&#34;&#34;
        for r in self:
            r.del_activation()

    def del_activation(self):
        &#34;&#34;&#34;Deletes the activation vector&#39;s data of self, but not the object itself, so any computed attribute remains
        available&#34;&#34;&#34;
        if hasattr(self, &#34;_activation&#34;) and self._activation is not None:
            self._activation.delete()

    def del_stacked_activations(self):
        &#34;&#34;&#34;Deletes stacked activation vectors of self. Set it to None.&#34;&#34;&#34;
        if hasattr(self, &#34;stacked_activations&#34;) and self.stacked_activations is not None:
            del self.stacked_activations
            self.stacked_activations = None

    def evaluate(self, xs: Union[pd.DataFrame, np.ndarray]) -&gt; Activation:
        &#34;&#34;&#34;Computes and returns the activation vector from an array of features.

        Parameters
        ----------
        xs: Union[pd.DataFrame, np.ndarray]
            The features on which the check whether the rule is activated or not. Must be a 2-D np.ndarray
            or pd.DataFrame.

        Returns
        -------
        Activation
        &#34;&#34;&#34;
        if len(self) == 0:
            raise ValueError(&#34;Can not use evaluate : The ruleset is empty!&#34;)
        activations = [rule.evaluate_activation(xs) for rule in self.rules]
        return Activation.multi_logical_or(activations)

    def calc_activation(self, xs: Union[np.ndarray, pd.DataFrame]):
        &#34;&#34;&#34;Uses input xs features data to compute the activation vector of all rules in self, and updates self&#39;s
        activation and stacked activation if self.stack_activation is True

        Parameters
        ----------
        xs: Union[np.ndarray, pd.DataFrame]
        &#34;&#34;&#34;
        if len(self) == 0:
            raise ValueError(&#34;Can not use calc_activation : The ruleset is empty!&#34;)

        if len(xs) == 0:
            logger.warning(&#34;Given xs is empty&#34;)
            return
        [rule.calc_activation(xs) for rule in self.rules]

        self._activation = None
        self.compute_self_activation()
        if self.stack_activation:
            self.stacked_activations = None
            self.compute_stacked_activation()

    def get_features_count(self) -&gt; List[Tuple[Any, int]]:
        &#34;&#34;&#34;
        Get a counter of all different features in the ruleset. If names are not available, will use indexes.

        Returns:
        --------
        count : List[Tuple[Any, int]]
            Counter of all different features in the ruleset
        &#34;&#34;&#34;
        if len(self) == 0:
            return []
        if len(self.features_names) &gt; 0:
            var_in = list(itertools.chain(*[rule.features_names for rule in self]))
        else:
            var_in = list(itertools.chain(*[rule.feautres_indexes for rule in self]))
        count = Counter(var_in)

        count = count.most_common()
        return count

    def load(self, path, **kwargs):
        if hasattr(path, &#34;read&#34;):
            rules = path.read(**kwargs)
        else:
            rules = pd.read_csv(path, **kwargs)
        if &#34;ruleset coverage&#34; in rules.iloc[:, 0].values:
            self._coverage = rules[rules.iloc[:, 0] == &#34;ruleset coverage&#34;].iloc[0, 1]
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset coverage&#34;].index)
        if &#34;ruleset criterion&#34; in rules.iloc[:, 0].values:
            self.criterion = rules[rules.iloc[:, 0] == &#34;ruleset criterion&#34;].iloc[0, 1]
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset criterion&#34;].index)
        if &#34;ruleset train set size&#34; in rules.iloc[:, 0].values:
            self.train_set_size = rules[rules.iloc[:, 0] == &#34;ruleset train set size&#34;].iloc[0, 1]
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset train set size&#34;].index)
            if isinstance(self.train_set_size, str):
                self.train_set_size = int(self.train_set_size)
        if &#34;ruleset test set size&#34; in rules.iloc[:, 0].values:
            self.test_set_size = rules[rules.iloc[:, 0] == &#34;ruleset test set size&#34;].iloc[0, 1]
            if isinstance(self.test_set_size, str):
                self.test_set_size = int(self.test_set_size)
            rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset test set size&#34;].index)
        if rules.empty:
            self._rules = []
        else:
            self._rules = [self.series_to_rule(rules.loc[r]) for r in rules.index]
        for r in self:
            if r._train_set_size is None:
                r._train_set_size = self.train_set_size
            elif isinstance(r._train_set_size, str):
                r._train_set_size = int(r._train_set_size)
            if r._test_set_size is None:
                r._test_set_size = self.test_set_size
            elif isinstance(r._test_set_size, str):
                r._test_set_size = int(r._test_set_size)

        if len(self._rules) &gt; 0:
            self.rule_type = type(self._rules[0])
        self.compute_self_activation()
        if self.stack_activation:
            self.compute_stacked_activation()
        self.features_names = list(set(traverse([rule.features_names for rule in self])))

    def to_df(self) -&gt; pd.DataFrame:
        if len(self) == 0:
            return pd.DataFrame()
        idx = copy(self._rule_type.index)

        dfs = [
            self.rule_to_series(
                (i, r),
                index=idx,
            )
            for i, r in enumerate(self.rules)
        ]
        if len(dfs) &gt; 0:
            df = pd.concat(dfs, axis=1).T
        else:
            df = pd.DataFrame(columns=idx)

        s_cov = pd.DataFrame(
            columns=df.columns,
            data=[[self.ruleset_coverage if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset coverage&#34;],
        )
        s_crit = pd.DataFrame(
            columns=df.columns,
            data=[[self.criterion if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset criterion&#34;],
        )
        s_train = pd.DataFrame(
            columns=df.columns,
            data=[[self.train_set_size if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset train set size&#34;],
        )
        s_test = pd.DataFrame(
            columns=df.columns,
            data=[[self.train_set_size if i == 0 else np.nan for i in range(len(df.columns))]],
            index=[&#34;ruleset test set size&#34;],
        )
        return pd.concat([df, s_cov, s_crit, s_train, s_test])

    def save(self, path):
        df = self.to_df()

        if hasattr(path, &#34;write&#34;):
            path.write(df)
        else:
            df.to_csv(path)

    # noinspection PyProtectedMember
    @staticmethod
    def rule_to_series(irule: Tuple[int, Rule], index: list) -&gt; pd.Series:
        i = irule[0]
        rule = irule[1]
        if hasattr(rule, &#34;sign&#34;):
            name = f&#34;R_{i}({len(rule)}){rule.sign}&#34;
        else:
            name = f&#34;R_{i}({len(rule)})&#34;
        sr = pd.Series(data=[str(getattr(rule, ind)) for ind in index], name=name, index=index, dtype=str)
        return sr

    @staticmethod
    def series_to_rule(srule: pd.Series) -&gt; Rule:

        for ind in srule.index:
            if ind == &#34;Unnamed: 0&#34;:
                continue
            if ind not in Rule.index and ind not in RegressionRule.index and ind not in ClassificationRule.index:
                raise IndexError(f&#34;Invalid rule attribute &#39;{ind}&#39;&#34;)

        if &#34;std&#34; in srule.index:
            rule = RegressionRule()
        elif &#34;criterion&#34; in srule.index:
            rule = ClassificationRule()
        else:
            rule = Rule()
        rule_idx = copy(rule.__class__.rule_index)
        condition_index = {c: None for c in rule.__class__.condition_index}

        for rule_ind in srule.index:
            str_value = str(srule[rule_ind])
            if rule_ind in condition_index:
                condition_index[rule_ind] = ast.literal_eval(str_value)
            elif rule_ind in rule_idx:
                if rule_ind == &#34;activation&#34;:
                    setattr(rule, f&#34;_{rule_ind}&#34;, Activation(str_value))
                elif str_value == &#34;nan&#34;:
                    setattr(rule, f&#34;_{rule_ind}&#34;, np.nan)
                elif rule_ind == &#34;sign&#34;:
                    setattr(rule, f&#34;_{rule_ind}&#34;, str_value)
                else:
                    if rule_ind == &#34;prediction&#34;:  # Prediction can be a str in case of classification
                        try:
                            setattr(rule, f&#34;_{rule_ind}&#34;, ast.literal_eval(str_value))
                        except ValueError:
                            setattr(rule, f&#34;_{rule_ind}&#34;, str_value)
                    else:
                        setattr(rule, f&#34;_{rule_ind}&#34;, ast.literal_eval(str_value))
            else:
                continue

        rule._condition = HyperrectangleCondition(**condition_index)
        if hasattr(rule, rule.__class__.fitted_if_has) and getattr(rule, rule.__class__.fitted_if_has) is not None:
            rule._fitted = True
        return rule

    def calc_predictions(
        self, y: [np.ndarray, pd.Series], stacked_activations: Optional[pd.DataFrame] = None
    ) -&gt; Union[pd.Series, pd.DataFrame]:
        &#34;&#34;&#34;
        Will compute the prediction of each rule in the ruleset. Does NOT set anything in either the rules nor the
        ruleset.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
            The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
            np.ndarray or pd.Series.
        stacked_activations: Optional[pd.DataFrame)
            If specified, uses this activation instead of self.activation

        Returns
        -------
        Union[pd.Series, pd.DataFrame]
            Regression : A pd.Series with the rules as index and the values being the predictions\n
            Classification : A pd.DataFrame with rules as index and classes as columns, and class probabilities as
            values
        &#34;&#34;&#34;
        if stacked_activations is None:
            stacked_activations = self.stacked_activations
            if stacked_activations is None:
                raise ValueError(&#34;Stacked activation vectors are needed&#34;)

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
            if len(self) == 0:
                if self.rule_type is None:
                    return pd.Series(dtype=int)
                elif issubclass(self.rule_type, ClassificationRule):
                    return pd.DataFrame(dtype=int)
                elif issubclass(self.rule_type, RegressionRule):
                    return pd.Series(dtype=int)
                else:
                    raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

            if issubclass(self.rule_type, ClassificationRule):
                class_probabilities = functions.class_probabilities(stacked_activations, y)
                maxs = class_probabilities.max()
                return class_probabilities[class_probabilities == maxs].apply(
                    lambda x: x.dropna().sort_index().index[0]
                )
            elif issubclass(self.rule_type, RegressionRule):
                return functions.conditional_mean(stacked_activations, y)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_stds(self, y: [np.ndarray, pd.Series], stacked_activations: Optional[pd.DataFrame] = None) -&gt; pd.Series:
        &#34;&#34;&#34;
        Will compute the std of each rule in the ruleset. Does NOT set anything in either the rules nor the
        ruleset.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
          The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D np.ndarray
          or pd.Series.
        stacked_activations: Optional[pd.DataFrame]
            If specified, uses this activation instead of self.activation

        Returns
        -------
        pd.Series
            A pd.Series with the rules as index and the values being the std
        &#34;&#34;&#34;
        if not issubclass(self.rule_type, RegressionRule):
            raise TypeError(f&#34;&#39;std&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)

        if stacked_activations is None:
            stacked_activations = self.stacked_activations
            if stacked_activations is None:
                raise ValueError(&#34;Stacked activation vectors are needed&#34;)

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
            if len(self) == 0:
                if self._rule_type is None:
                    return pd.Series(dtype=int)
                elif issubclass(self.rule_type, RegressionRule):
                    return pd.Series(dtype=int)
                else:
                    raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

            if issubclass(self.rule_type, RegressionRule):
                return functions.conditional_std(stacked_activations, y)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_signs(self, predictions: Optional[pd.Series] = None) -&gt; pd.Series:
        &#34;&#34;&#34;
        Computes the sign of each rule in the ruleset.

        Rules predictions must have been set or be given to the method.
        &#34;&#34;&#34;
        if issubclass(self.rule_type, RegressionRule):
            if predictions is None:
                predictions = pd.Series({str(r.condition): r.prediction for r in self})
            return predictions.apply(lambda x: None if x is None else (&#34;-&#34; if x &lt; 0 else &#34;+&#34;))
        else:
            raise TypeError(f&#34;&#39;sign&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)

    def calc_zscores(
        self,
        y: np.ndarray,
        predictions: Optional[pd.Series] = None,
        nones: Optional[pd.Series] = None,
        horizon: int = 1,
    ) -&gt; pd.Series:
        if not issubclass(self.rule_type, RegressionRule):
            raise TypeError(f&#34;&#39;sign&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)
        if nones is None:
            nones = pd.Series({str(r.condition): r.nones for r in self})

        if predictions is None:
            predictions = self.calc_predictions(y=y)
            &#34;&#34;&#34;unique prediction of each rules in a pd.Series&#34;&#34;&#34;

        return calc_zscore_external(prediction=predictions, nones=nones, y=y, horizon=horizon)

    def calc_criterions(
        self,
        y: Union[np.ndarray, pd.Series],
        predictions: Optional[pd.Series] = None,
        stacked_activations: Optional[pd.DataFrame] = None,
        **kwargs,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;
        Will compute the criterion of each rule in the ruleset. Does NOT set anything in either the rules nor the
        ruleset.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
            The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
            np.ndarray or pd.Series.
        predictions: Optional[pd.Series]
            Prediction of each rules. If None, will call self.calc_predictions(y)
        stacked_activations: Optional[pd.DataFrame]
            If specified, uses those activations instead of self.stacked_activations
        kwargs

        Returns
        -------
        pd.Series
            Criterion values a set of rules (pd.Series)

        &#34;&#34;&#34;
        if stacked_activations is None:
            stacked_activations = self.stacked_activations
            if stacked_activations is None:
                raise ValueError(&#34;Stacked activation vectors are needed&#34;)

        if predictions is None:
            predictions = self.calc_predictions(y=y)
            &#34;&#34;&#34;unique prediction of each rules in a pd.Series&#34;&#34;&#34;

        if self._rule_type is None:
            return pd.Series(dtype=int)
        if issubclass(self.rule_type, ClassificationRule):
            return functions.calc_classification_criterion(stacked_activations, predictions, y, **kwargs)
        elif issubclass(self.rule_type, RegressionRule):
            return functions.calc_regression_criterion(
                stacked_activations.replace(0, np.nan) * predictions, y, **kwargs
            )
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_train_set_sizes(self, y: Union[np.ndarray, pd.Series]) -&gt; pd.Series:
        if isinstance(y, (pd.Series, pd.DataFrame)):
            s = len(y.index)
        else:
            s = len(y)
        return pd.Series({str(r.condition): s for r in self})

    def calc_test_set_sizes(self, y: Union[np.ndarray, pd.Series]) -&gt; pd.Series:
        if isinstance(y, (pd.Series, pd.DataFrame)):
            s = len(y.index)
        else:
            s = len(y)
        return pd.Series({str(r.condition): s for r in self})

    def predict(
        self,
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        weights: Optional[Union[pd.Series, str]] = None,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;Computes the prediction vector of an entier ruleset from its rules predictions and its activation vector.
        Predictions of rules must have been computed beforehand if &#39;xs&#39; is not specified.

        Parameters
        ----------
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
            If specified, uses those features to compute the ruleset&#39;s activation. Does not change the activation
            vectors nor the predictions of the ruleset&#39;s rules nor its own activation and stacked activations.
        weights: Optional[Union[pd.Series, str]]
            Optional weights. If is a pd.Series, expects the index to be the rules names. If is a str, a pd.Series
            will be constructed by fetching each rules&#39; attribute named after the given string
            (ex: it can be &#39;criterion&#39;)

        Returns
        -------
        pd.Series
            The prediction vector of the ruleset. Index are observations numbers, values are the predicted values when
            the ruleset predicts, else NaN.
        &#34;&#34;&#34;
        if len(self) == 0:
            return pd.Series(dtype=int)
        if self._rule_type is None:
            return pd.Series(dtype=int)

        stacked = self.__class__.STACKED_FIT and self.stacked_activations is not None

        stacked_activations = None
        if xs is not None and stacked:
            stacked_activations = self.evaluate_stacked_activations(xs=xs)
        if stacked:
            return self._calc_prediction_stacked(weights=weights, stacked_activations=stacked_activations)
        else:
            return self._calc_prediction_unstacked(weights=weights, xs=xs)

    def _calc_prediction_stacked(
        self, weights: Optional[Union[pd.Series, str]] = None, stacked_activations: Optional[pd.DataFrame] = None
    ) -&gt; Union[None, pd.Series]:
        predictions = pd.Series({str(r.condition): getattr(r, &#34;prediction&#34;) for r in self})

        if stacked_activations is None:
            stacked_activations = self.stacked_activations
        if stacked_activations is None:
            return None

        if isinstance(self[0].prediction, str):
            prediction_vectors = stacked_activations.replace(0, np.nan).replace(1.0, &#34;&#34;) + predictions
        else:
            prediction_vectors = stacked_activations.replace(0, np.nan) * predictions
        if prediction_vectors.empty:
            return prediction_vectors
        if weights is not None:
            if isinstance(weights, str):
                weights = pd.Series({str(r.condition): getattr(r, weights) for r in self})
            weights = stacked_activations.replace(0, np.nan) * weights
            if issubclass(self.rule_type, RegressionRule):
                return calc_ruleset_prediction_weighted_regressor_stacked(
                    prediction_vectors=prediction_vectors, weights=weights
                )
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_weighted_classificator_stacked(
                    prediction_vectors=prediction_vectors, weights=weights
                )
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)
        else:
            if issubclass(self.rule_type, RegressionRule):
                return calc_ruleset_prediction_equally_weighted_regressor_stacked(prediction_vectors=prediction_vectors)
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_equally_weighted_classificator_stacked(
                    prediction_vectors=prediction_vectors
                )
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def _calc_prediction_unstacked(
        self,
        weights: Optional[Union[pd.Series, str]] = None,
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
    ) -&gt; pd.Series:

        if weights is not None:
            if isinstance(weights, str):
                weights = pd.Series({str(r.condition): getattr(r, weights) for r in self})
            if issubclass(self.rule_type, RegressionRule):

                return calc_ruleset_prediction_weighted_regressor_unstacked(rules=self.rules, weights=weights, xs=xs)
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_weighted_classificator_unstacked(
                    rules=self.rules, weights=weights, xs=xs
                )
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)
        else:
            if issubclass(self.rule_type, RegressionRule):
                return calc_ruleset_prediction_equally_weighted_regressor_unstacked(rules=self.rules, xs=xs)
            elif issubclass(self.rule_type, ClassificationRule):
                return calc_ruleset_prediction_equally_weighted_classificator_unstacked(rules=self.rules, xs=xs)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_criterion(
        self,
        y: Union[np.ndarray, pd.Series],
        xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
        weights: Optional[Union[pd.Series, str]] = None,
        predictions: Optional[pd.Series] = None,
        **kwargs,
    ):
        &#34;&#34;&#34;Computes the criterion of an entier ruleset. Predictions of rules must have been computed beforehand.

        This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
        not suffice.

        Sets self.criterion so does not return anything

        Parameters
        ----------
        y: [np.ndarray, pd.Series]
            The targets on which to evaluate the ruleset criterions. Must be a 1-D np.ndarray or pd.Series.
        xs: Optional[Union[pd.DataFrame, np.ndarray]]
            If specified, uses those features to compute the ruleset&#39;s activation. Does not change the activation
            vectors nor the predictions of its rules. If specified and if self.stack_activation is True, will overwrite
            the ruleset&#39;s stacked activation vectors. Else, only ruleset&#39;s activation is overwritten.
        weights: Optional[Union[pd.Series, str]]
            Optional weights. If is a pd.Series, expected the index to be the rules names. If is a str, a pd.Series
            will be constructed by fetching each rules&#39; attribute named after the given string
            (ex: it can be &#39;criterion&#39;).
            Useless if predictions is specified.
        predictions: Optional[pd.Series]
            The vector of predictions of the ruleset. If not specified, is computed using self.calc_prediction
        kwargs
        &#34;&#34;&#34;
        if len(self) == 0:
            return np.nan
        if self._rule_type is None:
            return np.nan
        if predictions is None:
            predictions = self.predict(xs=xs, weights=weights)
        if len(predictions) == 0:
            self.criterion = np.nan
            return
        if issubclass(self.rule_type, ClassificationRule):
            if xs is not None:
                activation = self.evaluate_self_activation(xs=xs).raw
            else:
                if self._activation is None or self._activation.length == 0:
                    self.compute_self_activation()
                activation = self.activation
            self.criterion = functions.calc_classification_criterion(activation, predictions, y, **kwargs)
        elif issubclass(self.rule_type, RegressionRule):
            # noinspection PyTypeChecker
            self.criterion = functions.calc_regression_criterion(predictions, y, **kwargs)
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    def calc_test_set_size(self, y: Union[np.ndarray, pd.Series]):
        if isinstance(y, (pd.Series, pd.DataFrame)):
            self.test_set_size = len(y.index)
        else:
            self.test_set_size = len(y)

    def calc_train_set_size(self, y: Union[np.ndarray, pd.Series]):
        if isinstance(y, (pd.Series, pd.DataFrame)):
            self.train_set_size = len(y.index)
        else:
            self.train_set_size = len(y)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="ruleskit.ruleset.RuleSet.CHECK_DUPLICATED"><code class="name">var <span class="ident">CHECK_DUPLICATED</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ruleskit.ruleset.RuleSet.NLINES"><code class="name">var <span class="ident">NLINES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ruleskit.ruleset.RuleSet.STACKED_FIT"><code class="name">var <span class="ident">STACKED_FIT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ruleskit.ruleset.RuleSet.all_features_indexes"><code class="name">var <span class="ident">all_features_indexes</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ruleskit.ruleset.RuleSet.attributes_from_test_set"><code class="name">var <span class="ident">attributes_from_test_set</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ruleskit.ruleset.RuleSet.attributes_from_train_set"><code class="name">var <span class="ident">attributes_from_train_set</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="ruleskit.ruleset.RuleSet.check_duplicated_rules"><code class="name flex">
<span>def <span class="ident">check_duplicated_rules</span></span>(<span>rules, name_or_index: str = 'index')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def check_duplicated_rules(rules, name_or_index: str = &#34;index&#34;):
    if name_or_index == &#34;index&#34;:
        str_rules = [str(r.features_indexes) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in rules]
    else:
        str_rules = [str(r.features_names) + str(r.bmins) + str(r.bmaxs) + str(r.prediction) for r in rules]
    if len(set(str_rules)) &lt; len(str_rules):
        duplicated = {}
        for r in str_rules:
            if r not in duplicated:
                duplicated[r] = 0
            duplicated[r] += 1
        duplicated = [
            f&#34;{r}: {duplicated[r]} (positions {[i for i, x in enumerate(str_rules) if x == r]})\n&#34;
            f&#34;   underlying rules : {[str(rules[i]) for i in [i for i, x in enumerate(str_rules) if x == r]]}&#34;
            for r in duplicated
            if duplicated[r] &gt; 1
        ]
        s = &#34;\n -&#34;.join(duplicated)
        raise ValueError(f&#34;There are {len(duplicated)} duplicated rules in your ruleset !\n {s}&#34;)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.rule_to_series"><code class="name flex">
<span>def <span class="ident">rule_to_series</span></span>(<span>irule: Tuple[int, <a title="ruleskit.rule.Rule" href="rule.html#ruleskit.rule.Rule">Rule</a>], index: list) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def rule_to_series(irule: Tuple[int, Rule], index: list) -&gt; pd.Series:
    i = irule[0]
    rule = irule[1]
    if hasattr(rule, &#34;sign&#34;):
        name = f&#34;R_{i}({len(rule)}){rule.sign}&#34;
    else:
        name = f&#34;R_{i}({len(rule)})&#34;
    sr = pd.Series(data=[str(getattr(rule, ind)) for ind in index], name=name, index=index, dtype=str)
    return sr</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.series_to_rule"><code class="name flex">
<span>def <span class="ident">series_to_rule</span></span>(<span>srule: pandas.core.series.Series) ‑> <a title="ruleskit.rule.Rule" href="rule.html#ruleskit.rule.Rule">Rule</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def series_to_rule(srule: pd.Series) -&gt; Rule:

    for ind in srule.index:
        if ind == &#34;Unnamed: 0&#34;:
            continue
        if ind not in Rule.index and ind not in RegressionRule.index and ind not in ClassificationRule.index:
            raise IndexError(f&#34;Invalid rule attribute &#39;{ind}&#39;&#34;)

    if &#34;std&#34; in srule.index:
        rule = RegressionRule()
    elif &#34;criterion&#34; in srule.index:
        rule = ClassificationRule()
    else:
        rule = Rule()
    rule_idx = copy(rule.__class__.rule_index)
    condition_index = {c: None for c in rule.__class__.condition_index}

    for rule_ind in srule.index:
        str_value = str(srule[rule_ind])
        if rule_ind in condition_index:
            condition_index[rule_ind] = ast.literal_eval(str_value)
        elif rule_ind in rule_idx:
            if rule_ind == &#34;activation&#34;:
                setattr(rule, f&#34;_{rule_ind}&#34;, Activation(str_value))
            elif str_value == &#34;nan&#34;:
                setattr(rule, f&#34;_{rule_ind}&#34;, np.nan)
            elif rule_ind == &#34;sign&#34;:
                setattr(rule, f&#34;_{rule_ind}&#34;, str_value)
            else:
                if rule_ind == &#34;prediction&#34;:  # Prediction can be a str in case of classification
                    try:
                        setattr(rule, f&#34;_{rule_ind}&#34;, ast.literal_eval(str_value))
                    except ValueError:
                        setattr(rule, f&#34;_{rule_ind}&#34;, str_value)
                else:
                    setattr(rule, f&#34;_{rule_ind}&#34;, ast.literal_eval(str_value))
        else:
            continue

    rule._condition = HyperrectangleCondition(**condition_index)
    if hasattr(rule, rule.__class__.fitted_if_has) and getattr(rule, rule.__class__.fitted_if_has) is not None:
        rule._fitted = True
    return rule</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="ruleskit.ruleset.RuleSet.activation"><code class="name">var <span class="ident">activation</span> : Optional[None]</code></dt>
<dd>
<div class="desc"><p>Returns the Activation vector's data in a form of a 1-D np.ndarray, or None if not available.</p>
<h2 id="returns">Returns:</h2>
<p>Union[None, np.ndarray]
of the form [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, &hellip;]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def activation(self) -&gt; Union[None, np.ndarray]:
    &#34;&#34;&#34;Returns the Activation vector&#39;s data in a form of a 1-D np.ndarray, or None if not available.

    Returns:
    --------
    Union[None, np.ndarray]
        of the form [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, ...]
    &#34;&#34;&#34;
    if self._activation:
        return self._activation.raw
    return None</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.activation_available"><code class="name">var <span class="ident">activation_available</span> : bool</code></dt>
<dd>
<div class="desc"><p>Returns True if the RuleSet has an activation vector, and if this Activation's object data is available.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def activation_available(self) -&gt; bool:
    &#34;&#34;&#34;Returns True if the RuleSet has an activation vector, and if this Activation&#39;s object data is available.&#34;&#34;&#34;
    if self._activation is None or self._activation.length == 0:
        return False
    if self._activation.data_format == &#34;file&#34;:
        return self._activation.data.is_file()
    else:
        return self._activation.data is not None</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.rule_type"><code class="name">var <span class="ident">rule_type</span> : type</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def rule_type(self) -&gt; type:
    if self._rule_type is None:
        raise ValueError(&#34;Ruleset&#39;s rule type is not set !&#34;)
    return self._rule_type</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.rules"><code class="name">var <span class="ident">rules</span> : List[<a title="ruleskit.rule.Rule" href="rule.html#ruleskit.rule.Rule">Rule</a>]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def rules(self) -&gt; List[Rule]:
    return self._rules</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.ruleset_coverage"><code class="name">var <span class="ident">ruleset_coverage</span> : float</code></dt>
<dd>
<div class="desc"><p>Coverage is the fraction of points equal to 1 in the activation vector</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def ruleset_coverage(self) -&gt; float:
    &#34;&#34;&#34;Coverage is the fraction of points equal to 1 in the activation vector&#34;&#34;&#34;
    if not self.activation_available:
        return self._coverage
    else:
        return self._activation.coverage</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.stacked_activations_available"><code class="name">var <span class="ident">stacked_activations_available</span> : bool</code></dt>
<dd>
<div class="desc"><p>Returns True is the RuleSet has its rules' stacked activations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def stacked_activations_available(self) -&gt; bool:
    &#34;&#34;&#34;Returns True is the RuleSet has its rules&#39; stacked activations.&#34;&#34;&#34;
    if self.stack_activation is None or self._activation.length == 0:
        return False
    return True</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.test_set_size"><code class="name">var <span class="ident">test_set_size</span></code></dt>
<dd>
<div class="desc"><p>Set by self.eval</p></div>
</dd>
<dt id="ruleskit.ruleset.RuleSet.to_hash"><code class="name">var <span class="ident">to_hash</span> : Tuple[str]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def to_hash(self) -&gt; Tuple[str]:
    if len(self) == 0:
        return &#34;rs&#34;,
    to_hash = (&#34;rs&#34;,)
    for r in self:
        rule_hash = r.to_hash[1:]
        to_hash += rule_hash
    return to_hash</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="ruleskit.ruleset.RuleSet.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, rule: <a title="ruleskit.rule.Rule" href="rule.html#ruleskit.rule.Rule">Rule</a>, update_activation: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>Appends a new rule to self. The updates of activation vector and the stacked activation vectors can be
blocked by specifying update_activation=False. Otherwise, will use self.stack_activation to determine if the
updates should be done or not.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append(self, rule: Rule, update_activation: bool = True):
    &#34;&#34;&#34;Appends a new rule to self. The updates of activation vector and the stacked activation vectors can be
    blocked by specifying update_activation=False. Otherwise, will use self.stack_activation to determine if the
    updates should be done or not.&#34;&#34;&#34;
    if not isinstance(rule, Rule):
        raise TypeError(f&#34;RuleSet&#39;s append method expects a Rule object, got {type(rule)}&#34;)
    if self._rule_type is None:
        self.rule_type = type(rule)
    else:
        if not isinstance(rule, self.rule_type):
            raise TypeError(
                f&#34;Ruleset previously had rules of type {self.rule_type}, so can not add rule of type {type(rule)}&#34;
            )
    stack_activation = self.stack_activation
    if not update_activation:
        self._compute_activation = False
        self.stack_activation = False
    self.__iadd__(rule)
    self._compute_activation = True
    self.stack_activation = stack_activation</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_activation"><code class="name flex">
<span>def <span class="ident">calc_activation</span></span>(<span>self, xs: Union[pandas.core.frame.DataFrame, numpy.ndarray])</span>
</code></dt>
<dd>
<div class="desc"><p>Uses input xs features data to compute the activation vector of all rules in self, and updates self's
activation and stacked activation if self.stack_activation is True</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>xs</code></strong> :&ensp;<code>Union[np.ndarray, pd.DataFrame]</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_activation(self, xs: Union[np.ndarray, pd.DataFrame]):
    &#34;&#34;&#34;Uses input xs features data to compute the activation vector of all rules in self, and updates self&#39;s
    activation and stacked activation if self.stack_activation is True

    Parameters
    ----------
    xs: Union[np.ndarray, pd.DataFrame]
    &#34;&#34;&#34;
    if len(self) == 0:
        raise ValueError(&#34;Can not use calc_activation : The ruleset is empty!&#34;)

    if len(xs) == 0:
        logger.warning(&#34;Given xs is empty&#34;)
        return
    [rule.calc_activation(xs) for rule in self.rules]

    self._activation = None
    self.compute_self_activation()
    if self.stack_activation:
        self.stacked_activations = None
        self.compute_stacked_activation()</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_criterion"><code class="name flex">
<span>def <span class="ident">calc_criterion</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series], xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None, weights: Union[pandas.core.series.Series, str, ForwardRef(None)] = None, predictions: Optional[None] = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the criterion of an entier ruleset. Predictions of rules must have been computed beforehand.</p>
<p>This uses the ruleset's stacked activation, so do not use it with too large rulesets otherwise your memory might
not suffice.</p>
<p>Sets self.criterion so does not return anything</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>[np.ndarray, pd.Series]</code></dt>
<dd>The targets on which to evaluate the ruleset criterions. Must be a 1-D np.ndarray or pd.Series.</dd>
<dt><strong><code>xs</code></strong> :&ensp;<code>Optional[Union[pd.DataFrame, np.ndarray]]</code></dt>
<dd>If specified, uses those features to compute the ruleset's activation. Does not change the activation
vectors nor the predictions of its rules. If specified and if self.stack_activation is True, will overwrite
the ruleset's stacked activation vectors. Else, only ruleset's activation is overwritten.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>Optional[Union[pd.Series, str]]</code></dt>
<dd>Optional weights. If is a pd.Series, expected the index to be the rules names. If is a str, a pd.Series
will be constructed by fetching each rules' attribute named after the given string
(ex: it can be 'criterion').
Useless if predictions is specified.</dd>
<dt><strong><code>predictions</code></strong> :&ensp;<code>Optional[pd.Series]</code></dt>
<dd>The vector of predictions of the ruleset. If not specified, is computed using self.calc_prediction</dd>
<dt><strong><code>kwargs</code></strong></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_criterion(
    self,
    y: Union[np.ndarray, pd.Series],
    xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
    weights: Optional[Union[pd.Series, str]] = None,
    predictions: Optional[pd.Series] = None,
    **kwargs,
):
    &#34;&#34;&#34;Computes the criterion of an entier ruleset. Predictions of rules must have been computed beforehand.

    This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
    not suffice.

    Sets self.criterion so does not return anything

    Parameters
    ----------
    y: [np.ndarray, pd.Series]
        The targets on which to evaluate the ruleset criterions. Must be a 1-D np.ndarray or pd.Series.
    xs: Optional[Union[pd.DataFrame, np.ndarray]]
        If specified, uses those features to compute the ruleset&#39;s activation. Does not change the activation
        vectors nor the predictions of its rules. If specified and if self.stack_activation is True, will overwrite
        the ruleset&#39;s stacked activation vectors. Else, only ruleset&#39;s activation is overwritten.
    weights: Optional[Union[pd.Series, str]]
        Optional weights. If is a pd.Series, expected the index to be the rules names. If is a str, a pd.Series
        will be constructed by fetching each rules&#39; attribute named after the given string
        (ex: it can be &#39;criterion&#39;).
        Useless if predictions is specified.
    predictions: Optional[pd.Series]
        The vector of predictions of the ruleset. If not specified, is computed using self.calc_prediction
    kwargs
    &#34;&#34;&#34;
    if len(self) == 0:
        return np.nan
    if self._rule_type is None:
        return np.nan
    if predictions is None:
        predictions = self.predict(xs=xs, weights=weights)
    if len(predictions) == 0:
        self.criterion = np.nan
        return
    if issubclass(self.rule_type, ClassificationRule):
        if xs is not None:
            activation = self.evaluate_self_activation(xs=xs).raw
        else:
            if self._activation is None or self._activation.length == 0:
                self.compute_self_activation()
            activation = self.activation
        self.criterion = functions.calc_classification_criterion(activation, predictions, y, **kwargs)
    elif issubclass(self.rule_type, RegressionRule):
        # noinspection PyTypeChecker
        self.criterion = functions.calc_regression_criterion(predictions, y, **kwargs)
    else:
        raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_criterions"><code class="name flex">
<span>def <span class="ident">calc_criterions</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series], predictions: Optional[None] = None, stacked_activations: Optional[pandas.core.frame.DataFrame] = None, **kwargs) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Will compute the criterion of each rule in the ruleset. Does NOT set anything in either the rules nor the
ruleset.</p>
<p>This uses the ruleset's stacked activation, so do not use it with too large rulesets otherwise your memory might
not suffice.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>[np.ndarray, pd.Series]</code></dt>
<dd>The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
np.ndarray or pd.Series.</dd>
<dt><strong><code>predictions</code></strong> :&ensp;<code>Optional[pd.Series]</code></dt>
<dd>Prediction of each rules. If None, will call self.calc_predictions(y)</dd>
<dt><strong><code>stacked_activations</code></strong> :&ensp;<code>Optional[pd.DataFrame]</code></dt>
<dd>If specified, uses those activations instead of self.stacked_activations</dd>
<dt><strong><code>kwargs</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.Series</code></dt>
<dd>Criterion values a set of rules (pd.Series)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_criterions(
    self,
    y: Union[np.ndarray, pd.Series],
    predictions: Optional[pd.Series] = None,
    stacked_activations: Optional[pd.DataFrame] = None,
    **kwargs,
) -&gt; pd.Series:
    &#34;&#34;&#34;
    Will compute the criterion of each rule in the ruleset. Does NOT set anything in either the rules nor the
    ruleset.

    This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
    not suffice.

    Parameters
    ----------
    y: [np.ndarray, pd.Series]
        The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
        np.ndarray or pd.Series.
    predictions: Optional[pd.Series]
        Prediction of each rules. If None, will call self.calc_predictions(y)
    stacked_activations: Optional[pd.DataFrame]
        If specified, uses those activations instead of self.stacked_activations
    kwargs

    Returns
    -------
    pd.Series
        Criterion values a set of rules (pd.Series)

    &#34;&#34;&#34;
    if stacked_activations is None:
        stacked_activations = self.stacked_activations
        if stacked_activations is None:
            raise ValueError(&#34;Stacked activation vectors are needed&#34;)

    if predictions is None:
        predictions = self.calc_predictions(y=y)
        &#34;&#34;&#34;unique prediction of each rules in a pd.Series&#34;&#34;&#34;

    if self._rule_type is None:
        return pd.Series(dtype=int)
    if issubclass(self.rule_type, ClassificationRule):
        return functions.calc_classification_criterion(stacked_activations, predictions, y, **kwargs)
    elif issubclass(self.rule_type, RegressionRule):
        return functions.calc_regression_criterion(
            stacked_activations.replace(0, np.nan) * predictions, y, **kwargs
        )
    else:
        raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_predictions"><code class="name flex">
<span>def <span class="ident">calc_predictions</span></span>(<span>self, y: [<class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>], stacked_activations: Optional[pandas.core.frame.DataFrame] = None) ‑> Union[pandas.core.series.Series, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Will compute the prediction of each rule in the ruleset. Does NOT set anything in either the rules nor the
ruleset.</p>
<p>This uses the ruleset's stacked activation, so do not use it with too large rulesets otherwise your memory might
not suffice.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>[np.ndarray, pd.Series]</code></dt>
<dd>The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
np.ndarray or pd.Series.</dd>
<dt><strong><code>stacked_activations</code></strong> :&ensp;<code>Optional[pd.DataFrame)</code></dt>
<dd>If specified, uses this activation instead of self.activation</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[pd.Series, pd.DataFrame]</code></dt>
<dd>
<p>Regression : A pd.Series with the rules as index and the values being the predictions</p>
<p>Classification : A pd.DataFrame with rules as index and classes as columns, and class probabilities as
values</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_predictions(
    self, y: [np.ndarray, pd.Series], stacked_activations: Optional[pd.DataFrame] = None
) -&gt; Union[pd.Series, pd.DataFrame]:
    &#34;&#34;&#34;
    Will compute the prediction of each rule in the ruleset. Does NOT set anything in either the rules nor the
    ruleset.

    This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
    not suffice.

    Parameters
    ----------
    y: [np.ndarray, pd.Series]
        The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D
        np.ndarray or pd.Series.
    stacked_activations: Optional[pd.DataFrame)
        If specified, uses this activation instead of self.activation

    Returns
    -------
    Union[pd.Series, pd.DataFrame]
        Regression : A pd.Series with the rules as index and the values being the predictions\n
        Classification : A pd.DataFrame with rules as index and classes as columns, and class probabilities as
        values
    &#34;&#34;&#34;
    if stacked_activations is None:
        stacked_activations = self.stacked_activations
        if stacked_activations is None:
            raise ValueError(&#34;Stacked activation vectors are needed&#34;)

    with warnings.catch_warnings():
        warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
        if len(self) == 0:
            if self.rule_type is None:
                return pd.Series(dtype=int)
            elif issubclass(self.rule_type, ClassificationRule):
                return pd.DataFrame(dtype=int)
            elif issubclass(self.rule_type, RegressionRule):
                return pd.Series(dtype=int)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

        if issubclass(self.rule_type, ClassificationRule):
            class_probabilities = functions.class_probabilities(stacked_activations, y)
            maxs = class_probabilities.max()
            return class_probabilities[class_probabilities == maxs].apply(
                lambda x: x.dropna().sort_index().index[0]
            )
        elif issubclass(self.rule_type, RegressionRule):
            return functions.conditional_mean(stacked_activations, y)
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_signs"><code class="name flex">
<span>def <span class="ident">calc_signs</span></span>(<span>self, predictions: Optional[None] = None) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the sign of each rule in the ruleset.</p>
<p>Rules predictions must have been set or be given to the method.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_signs(self, predictions: Optional[pd.Series] = None) -&gt; pd.Series:
    &#34;&#34;&#34;
    Computes the sign of each rule in the ruleset.

    Rules predictions must have been set or be given to the method.
    &#34;&#34;&#34;
    if issubclass(self.rule_type, RegressionRule):
        if predictions is None:
            predictions = pd.Series({str(r.condition): r.prediction for r in self})
        return predictions.apply(lambda x: None if x is None else (&#34;-&#34; if x &lt; 0 else &#34;+&#34;))
    else:
        raise TypeError(f&#34;&#39;sign&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_stds"><code class="name flex">
<span>def <span class="ident">calc_stds</span></span>(<span>self, y: [<class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>], stacked_activations: Optional[pandas.core.frame.DataFrame] = None) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Will compute the std of each rule in the ruleset. Does NOT set anything in either the rules nor the
ruleset.</p>
<p>This uses the ruleset's stacked activation, so do not use it with too large rulesets otherwise your memory might
not suffice.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>[np.ndarray, pd.Series]</code></dt>
<dd>&nbsp;</dd>
<dt>The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D np.ndarray</dt>
<dt>or pd.Series.</dt>
<dt><strong><code>stacked_activations</code></strong> :&ensp;<code>Optional[pd.DataFrame]</code></dt>
<dd>If specified, uses this activation instead of self.activation</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.Series</code></dt>
<dd>A pd.Series with the rules as index and the values being the std</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_stds(self, y: [np.ndarray, pd.Series], stacked_activations: Optional[pd.DataFrame] = None) -&gt; pd.Series:
    &#34;&#34;&#34;
    Will compute the std of each rule in the ruleset. Does NOT set anything in either the rules nor the
    ruleset.

    This uses the ruleset&#39;s stacked activation, so do not use it with too large rulesets otherwise your memory might
    not suffice.

    Parameters
    ----------
    y: [np.ndarray, pd.Series]
      The targets on which to evaluate the rules predictions, and possibly other criteria. Must be a 1-D np.ndarray
      or pd.Series.
    stacked_activations: Optional[pd.DataFrame]
        If specified, uses this activation instead of self.activation

    Returns
    -------
    pd.Series
        A pd.Series with the rules as index and the values being the std
    &#34;&#34;&#34;
    if not issubclass(self.rule_type, RegressionRule):
        raise TypeError(f&#34;&#39;std&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)

    if stacked_activations is None:
        stacked_activations = self.stacked_activations
        if stacked_activations is None:
            raise ValueError(&#34;Stacked activation vectors are needed&#34;)

    with warnings.catch_warnings():
        warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
        if len(self) == 0:
            if self._rule_type is None:
                return pd.Series(dtype=int)
            elif issubclass(self.rule_type, RegressionRule):
                return pd.Series(dtype=int)
            else:
                raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

        if issubclass(self.rule_type, RegressionRule):
            return functions.conditional_std(stacked_activations, y)
        else:
            raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_test_set_size"><code class="name flex">
<span>def <span class="ident">calc_test_set_size</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_test_set_size(self, y: Union[np.ndarray, pd.Series]):
    if isinstance(y, (pd.Series, pd.DataFrame)):
        self.test_set_size = len(y.index)
    else:
        self.test_set_size = len(y)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_test_set_sizes"><code class="name flex">
<span>def <span class="ident">calc_test_set_sizes</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series]) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_test_set_sizes(self, y: Union[np.ndarray, pd.Series]) -&gt; pd.Series:
    if isinstance(y, (pd.Series, pd.DataFrame)):
        s = len(y.index)
    else:
        s = len(y)
    return pd.Series({str(r.condition): s for r in self})</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_train_set_size"><code class="name flex">
<span>def <span class="ident">calc_train_set_size</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_train_set_size(self, y: Union[np.ndarray, pd.Series]):
    if isinstance(y, (pd.Series, pd.DataFrame)):
        self.train_set_size = len(y.index)
    else:
        self.train_set_size = len(y)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_train_set_sizes"><code class="name flex">
<span>def <span class="ident">calc_train_set_sizes</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series]) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_train_set_sizes(self, y: Union[np.ndarray, pd.Series]) -&gt; pd.Series:
    if isinstance(y, (pd.Series, pd.DataFrame)):
        s = len(y.index)
    else:
        s = len(y)
    return pd.Series({str(r.condition): s for r in self})</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.calc_zscores"><code class="name flex">
<span>def <span class="ident">calc_zscores</span></span>(<span>self, y: numpy.ndarray, predictions: Optional[None] = None, nones: Optional[None] = None, horizon: int = 1) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_zscores(
    self,
    y: np.ndarray,
    predictions: Optional[pd.Series] = None,
    nones: Optional[pd.Series] = None,
    horizon: int = 1,
) -&gt; pd.Series:
    if not issubclass(self.rule_type, RegressionRule):
        raise TypeError(f&#34;&#39;sign&#39; can not be computed for &#39;{self.rule_type}&#39;&#34;)
    if nones is None:
        nones = pd.Series({str(r.condition): r.nones for r in self})

    if predictions is None:
        predictions = self.calc_predictions(y=y)
        &#34;&#34;&#34;unique prediction of each rules in a pd.Series&#34;&#34;&#34;

    return calc_zscore_external(prediction=predictions, nones=nones, y=y, horizon=horizon)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.compute_self_activation"><code class="name flex">
<span>def <span class="ident">compute_self_activation</span></span>(<span>self, xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the activation vector of self from its rules. If xs is specified, uses it to remake the
rules' activation vectors, but do not set them as the 'activation' attributes of the rules</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_self_activation(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
    &#34;&#34;&#34;Computes the activation vector of self from its rules. If xs is specified, uses it to remake the
    rules&#39; activation vectors, but do not set them as the &#39;activation&#39; attributes of the rules&#34;&#34;&#34;
    self._activation = self.evaluate_self_activation(xs=xs)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.compute_stacked_activation"><code class="name flex">
<span>def <span class="ident">compute_stacked_activation</span></span>(<span>self, xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the stacked activation vectors of self from its rules. If xs is specified, uses it to remake the
rules' activation vectors, but do not set them as the 'activation' attributes of the rules</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_stacked_activation(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
    &#34;&#34;&#34;Computes the stacked activation vectors of self from its rules. If xs is specified, uses it to remake the
    rules&#39; activation vectors, but do not set them as the &#39;activation&#39; attributes of the rules&#34;&#34;&#34;
    self.stacked_activations = self.evaluate_stacked_activations(xs=xs)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.del_activation"><code class="name flex">
<span>def <span class="ident">del_activation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Deletes the activation vector's data of self, but not the object itself, so any computed attribute remains
available</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def del_activation(self):
    &#34;&#34;&#34;Deletes the activation vector&#39;s data of self, but not the object itself, so any computed attribute remains
    available&#34;&#34;&#34;
    if hasattr(self, &#34;_activation&#34;) and self._activation is not None:
        self._activation.delete()</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.del_activations"><code class="name flex">
<span>def <span class="ident">del_activations</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Deletes the data, but not the relevent attributes, of the activation vector or each rules in self.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def del_activations(self):
    &#34;&#34;&#34;Deletes the data, but not the relevent attributes, of the activation vector or each rules in self.&#34;&#34;&#34;
    for r in self:
        r.del_activation()</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.del_stacked_activations"><code class="name flex">
<span>def <span class="ident">del_stacked_activations</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Deletes stacked activation vectors of self. Set it to None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def del_stacked_activations(self):
    &#34;&#34;&#34;Deletes stacked activation vectors of self. Set it to None.&#34;&#34;&#34;
    if hasattr(self, &#34;stacked_activations&#34;) and self.stacked_activations is not None:
        del self.stacked_activations
        self.stacked_activations = None</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.eval"><code class="name flex">
<span>def <span class="ident">eval</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series], xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None, keep_new_activations: bool = False, weights: Union[pandas.core.series.Series, str, ForwardRef(None)] = None, force_if_not_good: bool = False, **kwargs) ‑> List[<a title="ruleskit.rule.Rule" href="rule.html#ruleskit.rule.Rule">Rule</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the ruleset on y and xs to produce the rules' attributes relevant to the test set. Will recompute
the ruleset's stacked activation vector if using stakced fit.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>Union[np.ndarray, pd.Series]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>xs</code></strong> :&ensp;<code>Optional[Union[pd.DataFrame, np.ndarray]]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>keep_new_activations</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, activation vectgor and stacked activation vectors will be kept as ruleset's attribute and replace
the ones computed using the train set, if any. Will also change the activation vectors of the rules.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>Optional[Union[pd.Series, str]]</code></dt>
<dd>Optional weights for calc_critetion. If is a pd.Series, expects the index to be the rules names.
If is a str, a pd.Series will be constructed by fetching each rules' attribute named after the given string
(ex: it can be 'criterion')</dd>
<dt><strong><code>force_if_not_good</code></strong> :&ensp;<code>bool</code></dt>
<dd>If the rule was seen as "bad", eval will not trigger unless this boolean is True (Default value = False)</dd>
<dt><strong><code>kwargs</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Rule]</code></dt>
<dd>List of rules that were excluded from the ruleset after fitting because they were 'bad'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval(
    self,
    y: Union[np.ndarray, pd.Series],
    xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
    keep_new_activations: bool = False,
    weights: Optional[Union[pd.Series, str]] = None,
    force_if_not_good: bool = False,
    **kwargs,
) -&gt; List[Rule]:
    &#34;&#34;&#34;Evaluate the ruleset on y and xs to produce the rules&#39; attributes relevant to the test set. Will recompute
    the ruleset&#39;s stacked activation vector if using stakced fit.

    Parameters
    ----------
    y: Union[np.ndarray, pd.Series]
    xs: Optional[Union[pd.DataFrame, np.ndarray]]
    keep_new_activations: bool
        If True, activation vectgor and stacked activation vectors will be kept as ruleset&#39;s attribute and replace
        the ones computed using the train set, if any. Will also change the activation vectors of the rules.
    weights: Optional[Union[pd.Series, str]]
        Optional weights for calc_critetion. If is a pd.Series, expects the index to be the rules names.
        If is a str, a pd.Series will be constructed by fetching each rules&#39; attribute named after the given string
        (ex: it can be &#39;criterion&#39;)
    force_if_not_good: bool
        If the rule was seen as &#34;bad&#34;, eval will not trigger unless this boolean is True (Default value = False)
    kwargs


    Returns
    -------
    List[Rule]
        List of rules that were excluded from the ruleset after fitting because they were &#39;bad&#39;
    &#34;&#34;&#34;
    if issubclass(self.rule_type, ClassificationRule):
        type_to_use = ClassificationRule
    elif issubclass(self.rule_type, RegressionRule):
        type_to_use = RegressionRule
    else:
        raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    if &#34;method&#34; in kwargs:
        raise IndexError(&#34;Key &#39;method&#39; can not be given to &#39;eval&#39;&#34;)

    def launch_method(method, **kw):
        expected_args = list(inspect.signature(method).parameters)
        if &#34;kwargs&#34; not in expected_args:
            kw = {item: kw[item] for item in kw if item in expected_args}
        return method(**kw)

    if xs is not None and len(xs) == 0:
        logger.warning(&#34;Given xs is empty&#34;)
        return []

    if len(self) == 0:
        logger.debug(&#34;Ruleset is empty. Nothing to fit.&#34;)
        return []

    if not all([r._fitted for r in self]):
        if xs is None:
            raise ValueError(
                &#34;Not all rules of the ruleset were fitted. Please do so before calling ruleset.eval or provide xs.&#34;
            )
        else:
            keep_new_activations = True

    if self.__class__.STACKED_FIT:
        clean_activation = False

        # If test set is given, compute the activation used to evaluate test relative attributes.
        # Not the same as self.stacked_activations, computed from the train set.
        # Else, we evaluate on the train set, so we use self.stacked_actviation
        nones = None
        if xs is not None:
            if keep_new_activations:
                clean_activation = not self.stack_activation
                self.stack_activation = True
                self.calc_activation(xs=xs)  # Will reset rules&#39; activation vectors too
                self.stack_activation = not clean_activation
                stacked_activations = self.stacked_activations
                activation = self._activation
                # noinspection PyUnresolvedReferences
                if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                    nones = pd.Series({str(r.condition): r.nones for r in self})
            else:
                stacked_activations = self.evaluate_stacked_activations(xs)
                # noinspection PyUnresolvedReferences
                if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                    activation, nones = self.evaluate_self_activation(xs, return_nones=True)
                else:
                    activation = self.evaluate_self_activation(xs)
        else:
            # If self.stacked_activations is None, compute it from the rules&#39; activations. They must be available.
            if self.stacked_activations is None:
                # Else, will compute the stacked activation from the current rules activations
                clean_activation = not self.stack_activation
                self.stack_activation = True
                self.compute_stacked_activation()
                self.compute_self_activation()
                if self.stacked_activations is None:
                    raise ValueError(&#34;Rules activations must have been computed previously.&#34;)
                self.stack_activation = not clean_activation
            stacked_activations = self.stacked_activations
            activation = self._activation
            # noinspection PyUnresolvedReferences
            if &#34;zscore&#34; in self.rule_type.attributes_from_test_set:
                nones = pd.Series({str(r.condition): r.nones for r in self})

        if isinstance(y, np.ndarray):
            if not len(stacked_activations.index) == y.shape[0]:
                raise IndexError(&#34;Stacked activation and y have different number of rows.&#34;)
        else:
            if not len(stacked_activations.index) == len(y.index):
                raise IndexError(&#34;Stacked activation and y have different number of rows.&#34;)
            stacked_activations.index = y.index

        # noinspection PyUnresolvedReferences
        if &#34;prediction&#34; in self.rule_type.attributes_from_train_set:
            # Do NOT recompute prediction from test set : it does not make sense !
            predictions = pd.Series({str(r.condition): r.prediction for r in self})
        else:
            predictions = None
        computed_attrs = {}

        # noinspection PyUnresolvedReferences
        for attr in self.rule_type.attributes_from_test_set:
            if attr == &#34;activation&#34;:
                raise ValueError(&#34;&#39;activation&#39; can not be specified in &#39;attributes_from_train_set&#39;&#34;)
            computed_attrs[f&#34;{attr}s&#34;] = launch_method(
                getattr(self, f&#34;calc_{attr}s&#34;),
                y=y,
                xs=xs,
                stacked_activations=stacked_activations,
                activation=activation,
                nones=nones,
                predictions=predictions,
                **computed_attrs,
                **kwargs,
            )

        to_drop = []

        if clean_activation:
            self.del_stacked_activations()
        else:
            if isinstance(y, np.ndarray):
                stacked_activations.index = pd.RangeIndex(y.shape[0])
            else:
                stacked_activations.index = pd.RangeIndex(len(y.index))

        for ir in range(len(self)):
            self._rules[ir]._evaluated = True
            for attr in computed_attrs:
                setattr(self._rules[ir], f&#34;_{attr[:-1]}&#34;, computed_attrs[attr].iloc[ir])
                if self._rules[ir].good:
                    self._rules[ir].check_thresholds(attr[:-1])
                if not self._rules[ir].good:
                    to_drop.append(self._rules[ir])
            if self._rules[ir].good:
                self._rules[ir].check_thresholds()
    else:
        [
            r.eval(
                xs=xs, y=y, recompute_activation=keep_new_activations,
                force_if_not_good=force_if_not_good, **kwargs
            ) for r in self
        ]
        to_drop = [r for r in self if not r.good]

    if len(to_drop) &gt; 0:
        rules = [r for r in self.rules if r not in to_drop]
        self._rules = []
        if self._activation is not None:
            self._activation.clear()
        self.del_stacked_activations()
        for r in rules:
            self.append(r, update_activation=False)

        # Recompute activation now that bad rules have been droped
        if self._activation is None or self._activation.length == 0 or (xs is not None and keep_new_activations):
            self._activation = None
            self.compute_self_activation()
        if self.stack_activation and (
            self.stacked_activations is None or (xs is not None and keep_new_activations)
        ):
            self.stacked_activations = None
            self.compute_stacked_activation()
    # If not bad rules were dropped and stacked fit was not used, still compute self.activation since it has not
    # been done
    elif not self.__class__.STACKED_FIT:
        if self._activation is None or self._activation.length == 0 or (xs is not None and keep_new_activations):
            self._activation = None
            self.compute_self_activation()
        if self.stack_activation and (self._activation is None or (xs is not None and keep_new_activations)):
            self.stacked_activations = None
            self.compute_stacked_activation()

    for attr in self.__class__.attributes_from_test_set[type_to_use]:
        launch_method(
            getattr(self, f&#34;calc_{attr}&#34;),
            y=y,
            xs=xs if not keep_new_activations else None,
            weights=weights,
            **kwargs,
        )

    return to_drop</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, xs: Union[pandas.core.frame.DataFrame, numpy.ndarray]) ‑> <a title="ruleskit.activation.Activation" href="activation.html#ruleskit.activation.Activation">Activation</a></span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the activation vector from an array of features.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>xs</code></strong> :&ensp;<code>Union[pd.DataFrame, np.ndarray]</code></dt>
<dd>The features on which the check whether the rule is activated or not. Must be a 2-D np.ndarray
or pd.DataFrame.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Activation</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, xs: Union[pd.DataFrame, np.ndarray]) -&gt; Activation:
    &#34;&#34;&#34;Computes and returns the activation vector from an array of features.

    Parameters
    ----------
    xs: Union[pd.DataFrame, np.ndarray]
        The features on which the check whether the rule is activated or not. Must be a 2-D np.ndarray
        or pd.DataFrame.

    Returns
    -------
    Activation
    &#34;&#34;&#34;
    if len(self) == 0:
        raise ValueError(&#34;Can not use evaluate : The ruleset is empty!&#34;)
    activations = [rule.evaluate_activation(xs) for rule in self.rules]
    return Activation.multi_logical_or(activations)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.evaluate_self_activation"><code class="name flex">
<span>def <span class="ident">evaluate_self_activation</span></span>(<span>self, xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None, return_nones: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the activation vector of self from its rules, using time-efficient Activation.multi_logical_or.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate_self_activation(
        self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None, return_nones: bool = False
):
    &#34;&#34;&#34;Computes the activation vector of self from its rules, using time-efficient Activation.multi_logical_or.&#34;&#34;&#34;
    if len(self) == 0:
        act = Activation(np.array([]))
        if return_nones is True:
            return act, pd.Series(dtype=int)
        return act
    if xs is not None:
        activations = [r.evaluate_activation(xs) for r in self]
        activations_available = True
    else:
        activations = [r._activation for r in self]
        activations_available = all([r.activation_available for r in self])
    if activations_available:
        if len(self) == 1:
            act = Activation(activations[0].raw, optimize=activations[0].optimize, to_file=activations[0].to_file)
            if return_nones is True:
                return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
            return act
        try:
            act = Activation.multi_logical_or(activations)
            if return_nones is True:
                return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
            return act
        except (MemoryError, np.core._exceptions._ArrayMemoryError):
            act = Activation(activations[0], optimize=activations[0].optimize, to_file=activations[0].to_file)
            for a in activations:
                act = act or a
            if return_nones is True:
                return act, pd.Series({str(self[i].condition): activations[i].nones for i in range(len(self))})
            return act</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.evaluate_stacked_activations"><code class="name flex">
<span>def <span class="ident">evaluate_stacked_activations</span></span>(<span>self, xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate_stacked_activations(self, xs: Optional[Union[np.ndarray, pd.DataFrame]] = None):
    if len(self) == 0:
        return pd.DataFrame(dtype=int)
    if xs is not None:
        return pd.DataFrame({str(r.condition): r.evaluate_activation(xs).raw for r in self})
    activations_available = all([r.activation_available for r in self])
    if activations_available:
        # noinspection PyProtectedMember
        return pd.DataFrame({str(r.condition): r.activation for r in self})</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, y: Union[numpy.ndarray, pandas.core.series.Series], xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None, force_if_not_good: bool = False, **kwargs) ‑> List[<a title="ruleskit.rule.Rule" href="rule.html#ruleskit.rule.Rule">Rule</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Fits the ruleset on y and xs to produce the rules' activation vectors and attributes relevant to train set.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>Union[np.ndarray, pd.Series]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>xs</code></strong> :&ensp;<code>Optional[Union[pd.DataFrame, np.ndarray]]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>force_if_not_good</code></strong> :&ensp;<code>bool</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>kwargs</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Rule]</code></dt>
<dd>List of rules that were excluded from the ruleset after fitting because they were 'bad'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(
    self,
    y: Union[np.ndarray, pd.Series],
    xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
    force_if_not_good: bool = False,
    **kwargs,
) -&gt; List[Rule]:
    &#34;&#34;&#34;Fits the ruleset on y and xs to produce the rules&#39; activation vectors and attributes relevant to train set.

    Parameters
    ----------
    y: Union[np.ndarray, pd.Series]
    xs: Optional[Union[pd.DataFrame, np.ndarray]]
    force_if_not_good: bool
    kwargs

    Returns
    -------
    List[Rule]
        List of rules that were excluded from the ruleset after fitting because they were &#39;bad&#39;
    &#34;&#34;&#34;
    if issubclass(self.rule_type, ClassificationRule):
        type_to_use = ClassificationRule
    elif issubclass(self.rule_type, RegressionRule):
        type_to_use = RegressionRule
    else:
        raise TypeError(f&#34;Unexpected rule type &#39;{self.rule_type}&#39;&#34;)

    if &#34;method&#34; in kwargs:
        raise IndexError(&#34;Key &#39;method&#39; can not be given to &#39;fit&#39;&#34;)

    def launch_method(method, **kw):
        expected_args = list(inspect.signature(method).parameters)
        if &#34;kwargs&#34; not in expected_args:
            kw = {item: kw[item] for item in kw if item in expected_args}
        return method(**kw)

    if xs is not None and len(xs) == 0:
        logger.warning(&#34;Given xs is empty&#34;)
        return []

    if len(self) == 0:
        logger.debug(&#34;Ruleset is empty. Nothing to fit.&#34;)
        return []

    if all([r._fitted for r in self]) and xs is None:
        return []

    if self.__class__.STACKED_FIT:

        clean_activation = False
        # Activation must always be computed from train set
        if xs is not None:
            clean_activation = not self.stack_activation
            self.stack_activation = True
            self.calc_activation(xs)
            self.stack_activation = not clean_activation
        elif self.stacked_activations is None:
            clean_activation = not self.stack_activation
            self.stack_activation = True
            self.compute_stacked_activation()
            self.stack_activation = not clean_activation

        if isinstance(y, np.ndarray):
            # noinspection PyUnresolvedReferences
            if not len(self.stacked_activations.index) == y.shape[0]:
                raise IndexError(
                    &#34;Stacked activation and y have different number of rows. Use pd.Series for y to&#34;
                    &#34; reindex stacked activations automatically.&#34;
                )
        else:
            self.stacked_activations.index = y.index

        computed_attrs = {}
        # noinspection PyUnresolvedReferences
        for attr in self.rule_type.attributes_from_train_set:
            if attr == &#34;activation&#34;:
                raise ValueError(&#34;&#39;activation&#39; can not be specified in &#39;attributes_from_train_set&#39;&#34;)
            computed_attrs[f&#34;{attr}s&#34;] = launch_method(
                getattr(self, f&#34;calc_{attr}s&#34;), y=y, xs=xs, **computed_attrs, **kwargs
            )
        to_drop = []

        if clean_activation:
            self.del_stacked_activations()
        else:
            if isinstance(y, np.ndarray):
                self.stacked_activations.index = pd.RangeIndex(y.shape[0])
            else:
                self.stacked_activations.index = pd.RangeIndex(len(y.index))

        for ir in range(len(self)):
            self._rules[ir]._fitted = True
            for attr in computed_attrs:
                setattr(self._rules[ir], f&#34;_{attr[:-1]}&#34;, computed_attrs[attr].iloc[ir])
                if self._rules[ir].good:
                    self._rules[ir].check_thresholds(attr[:-1])
                if not self._rules[ir].good:
                    to_drop.append(self._rules[ir])
            # To check attributes that are set along side others, like coverage
            if self._rules[ir].good:
                self._rules[ir].check_thresholds()
    else:
        [r.fit(xs=xs, y=y, force_if_not_good=force_if_not_good, **kwargs) for r in self]
        to_drop = [r for r in self if not r.good]

    if len(to_drop) &gt; 0:
        rules = [r for r in self.rules if r not in to_drop]
        self._rules = []
        if self._activation is not None:
            self._activation.clear()
        self.del_stacked_activations()
        for r in rules:
            self.append(r, update_activation=False)

        # Recompute activation now that bad rules have been droped
        self._activation = None
        self.compute_self_activation()
        if self.stack_activation:
            self.stacked_activations = None
            self.compute_stacked_activation()
    # If not bad rules were dropped and stacked fit was not used, still compute self.activation since it has not
    # been done  (needed to set self.coverage), but not stacked (useless)
    elif not self.__class__.STACKED_FIT:
        if self._activation is None or self._activation.length == 0 or xs is not None:
            self._activation = None
            self.compute_self_activation()
        if self.stack_activation and (self.stacked_activations is None or xs is not None):
            self.stacked_activations = None
            self.compute_stacked_activation()

    for attr in self.__class__.attributes_from_train_set[type_to_use]:
        launch_method(
            getattr(self, f&#34;calc_{attr}&#34;),
            y=y,
            xs=xs,
            **kwargs,
        )

    return to_drop</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.get_features_count"><code class="name flex">
<span>def <span class="ident">get_features_count</span></span>(<span>self) ‑> List[Tuple[Any, int]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get a counter of all different features in the ruleset. If names are not available, will use indexes.</p>
<h2 id="returns">Returns:</h2>
<p>count : List[Tuple[Any, int]]
Counter of all different features in the ruleset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_features_count(self) -&gt; List[Tuple[Any, int]]:
    &#34;&#34;&#34;
    Get a counter of all different features in the ruleset. If names are not available, will use indexes.

    Returns:
    --------
    count : List[Tuple[Any, int]]
        Counter of all different features in the ruleset
    &#34;&#34;&#34;
    if len(self) == 0:
        return []
    if len(self.features_names) &gt; 0:
        var_in = list(itertools.chain(*[rule.features_names for rule in self]))
    else:
        var_in = list(itertools.chain(*[rule.feautres_indexes for rule in self]))
    count = Counter(var_in)

    count = count.most_common()
    return count</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self, path, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(self, path, **kwargs):
    if hasattr(path, &#34;read&#34;):
        rules = path.read(**kwargs)
    else:
        rules = pd.read_csv(path, **kwargs)
    if &#34;ruleset coverage&#34; in rules.iloc[:, 0].values:
        self._coverage = rules[rules.iloc[:, 0] == &#34;ruleset coverage&#34;].iloc[0, 1]
        rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset coverage&#34;].index)
    if &#34;ruleset criterion&#34; in rules.iloc[:, 0].values:
        self.criterion = rules[rules.iloc[:, 0] == &#34;ruleset criterion&#34;].iloc[0, 1]
        rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset criterion&#34;].index)
    if &#34;ruleset train set size&#34; in rules.iloc[:, 0].values:
        self.train_set_size = rules[rules.iloc[:, 0] == &#34;ruleset train set size&#34;].iloc[0, 1]
        rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset train set size&#34;].index)
        if isinstance(self.train_set_size, str):
            self.train_set_size = int(self.train_set_size)
    if &#34;ruleset test set size&#34; in rules.iloc[:, 0].values:
        self.test_set_size = rules[rules.iloc[:, 0] == &#34;ruleset test set size&#34;].iloc[0, 1]
        if isinstance(self.test_set_size, str):
            self.test_set_size = int(self.test_set_size)
        rules = rules.drop(rules[rules.iloc[:, 0] == &#34;ruleset test set size&#34;].index)
    if rules.empty:
        self._rules = []
    else:
        self._rules = [self.series_to_rule(rules.loc[r]) for r in rules.index]
    for r in self:
        if r._train_set_size is None:
            r._train_set_size = self.train_set_size
        elif isinstance(r._train_set_size, str):
            r._train_set_size = int(r._train_set_size)
        if r._test_set_size is None:
            r._test_set_size = self.test_set_size
        elif isinstance(r._test_set_size, str):
            r._test_set_size = int(r._test_set_size)

    if len(self._rules) &gt; 0:
        self.rule_type = type(self._rules[0])
    self.compute_self_activation()
    if self.stack_activation:
        self.compute_stacked_activation()
    self.features_names = list(set(traverse([rule.features_names for rule in self])))</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, xs: Union[pandas.core.frame.DataFrame, numpy.ndarray, ForwardRef(None)] = None, weights: Union[pandas.core.series.Series, str, ForwardRef(None)] = None) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the prediction vector of an entier ruleset from its rules predictions and its activation vector.
Predictions of rules must have been computed beforehand if 'xs' is not specified.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>xs</code></strong> :&ensp;<code>Optional[Union[pd.DataFrame, np.ndarray]]</code></dt>
<dd>If specified, uses those features to compute the ruleset's activation. Does not change the activation
vectors nor the predictions of the ruleset's rules nor its own activation and stacked activations.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>Optional[Union[pd.Series, str]]</code></dt>
<dd>Optional weights. If is a pd.Series, expects the index to be the rules names. If is a str, a pd.Series
will be constructed by fetching each rules' attribute named after the given string
(ex: it can be 'criterion')</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.Series</code></dt>
<dd>The prediction vector of the ruleset. Index are observations numbers, values are the predicted values when
the ruleset predicts, else NaN.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(
    self,
    xs: Optional[Union[pd.DataFrame, np.ndarray]] = None,
    weights: Optional[Union[pd.Series, str]] = None,
) -&gt; pd.Series:
    &#34;&#34;&#34;Computes the prediction vector of an entier ruleset from its rules predictions and its activation vector.
    Predictions of rules must have been computed beforehand if &#39;xs&#39; is not specified.

    Parameters
    ----------
    xs: Optional[Union[pd.DataFrame, np.ndarray]]
        If specified, uses those features to compute the ruleset&#39;s activation. Does not change the activation
        vectors nor the predictions of the ruleset&#39;s rules nor its own activation and stacked activations.
    weights: Optional[Union[pd.Series, str]]
        Optional weights. If is a pd.Series, expects the index to be the rules names. If is a str, a pd.Series
        will be constructed by fetching each rules&#39; attribute named after the given string
        (ex: it can be &#39;criterion&#39;)

    Returns
    -------
    pd.Series
        The prediction vector of the ruleset. Index are observations numbers, values are the predicted values when
        the ruleset predicts, else NaN.
    &#34;&#34;&#34;
    if len(self) == 0:
        return pd.Series(dtype=int)
    if self._rule_type is None:
        return pd.Series(dtype=int)

    stacked = self.__class__.STACKED_FIT and self.stacked_activations is not None

    stacked_activations = None
    if xs is not None and stacked:
        stacked_activations = self.evaluate_stacked_activations(xs=xs)
    if stacked:
        return self._calc_prediction_stacked(weights=weights, stacked_activations=stacked_activations)
    else:
        return self._calc_prediction_unstacked(weights=weights, xs=xs)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, path)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, path):
    df = self.to_df()

    if hasattr(path, &#34;write&#34;):
        path.write(df)
    else:
        df.to_csv(path)</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.set_features_indexes"><code class="name flex">
<span>def <span class="ident">set_features_indexes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_features_indexes(self):
    if len(self.__class__.all_features_indexes) &gt; 0:
        self.features_indexes = [self.__class__.all_features_indexes[f] for f in self.features_names]
        for r in self._rules:
            # noinspection PyProtectedMember
            r._condition._features_indexes = [self.__class__.all_features_indexes[f] for f in r.features_names]
    else:
        list(set(itertools.chain(*[rule.features_indexes for rule in self])))</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.sort"><code class="name flex">
<span>def <span class="ident">sort</span></span>(<span>self, criterion: str = None, reverse: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Sorts the RuleSet.</p>
<ul>
<li>If criterion is not speficied:
Will sort the rules according to :
1. The number of features they talk about
2. For a same number of features (sorted in alphabetical order, or index if names are not available,
optionally reversed), the bmins and bmaxs of the rules</li>
<li>If criterion is specified, it must be an float or interger attribute of rule, condition or activation. Then
sorts according to this criterion, optionally reversed.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort(self, criterion: str = None, reverse: bool = False):
    &#34;&#34;&#34;Sorts the RuleSet.

    * If criterion is not speficied:
        Will sort the rules according to :
            1. The number of features they talk about
            2. For a same number of features (sorted in alphabetical order, or index if names are not available,
                optionally reversed), the bmins and bmaxs of the rules
    * If criterion is specified, it must be an float or interger attribute of rule, condition or activation. Then
        sorts according to this criterion, optionally reversed.
    &#34;&#34;&#34;
    if len(self) == 0:
        return

    if criterion is None or criterion == &#34;&#34;:
        if not (hasattr(self[0].condition, &#34;bmins&#34;) and hasattr(self[0].condition, &#34;bmaxs&#34;)):
            return
        # The set of all the features the RuleSet talks about
        which = &#34;index&#34;
        if len(self.features_names) &gt; 0:
            which = &#34;name&#34;
            fnames_or_indexes = list(set([str(r.features_names) for r in self]))
        else:
            fnames_or_indexes = list(set([str(r.features_indexes) for r in self]))
        dict_names = {}
        lmax = 1
        for f in fnames_or_indexes:
            l_ = len(ast.literal_eval(f))
            if l_ &gt; lmax:
                lmax = l_
            if l_ not in dict_names:
                dict_names[l_] = []
            dict_names[l_].append(f)
        for l_ in dict_names:
            dict_names[l_].sort(reverse=reverse)
        fnames_or_indexes = []
        for l_ in range(1, lmax + 1):
            if l_ in dict_names:
                fnames_or_indexes += dict_names[l_]

        rules_by_fnames = OrderedDict({f: [] for f in fnames_or_indexes})
        for rule in self:
            if which == &#34;name&#34;:
                v = str(rule.features_names)
            else:
                v = str(rule.features_indexes)
            rules_by_fnames[v].append(rule)
        rules_by_fnames = {
            n: sorted(rules_by_fnames[n], key=lambda x: x.condition.bmins + x.condition.bmaxs)
            for n in rules_by_fnames
        }
        self._rules = []
        for n in rules_by_fnames:
            self._rules += rules_by_fnames[n]
    elif hasattr(self[0], criterion):
        self._rules = sorted(self, key=lambda x: getattr(x, criterion), reverse=reverse)
    else:
        raise ValueError(f&#34;Can not sort RuleSet according to criterion {criterion}&#34;)
    if self.stack_activation:
        self.stacked_activations = self.stacked_activations[[str(r.condition) for r in self]]</code></pre>
</details>
</dd>
<dt id="ruleskit.ruleset.RuleSet.to_df"><code class="name flex">
<span>def <span class="ident">to_df</span></span>(<span>self) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_df(self) -&gt; pd.DataFrame:
    if len(self) == 0:
        return pd.DataFrame()
    idx = copy(self._rule_type.index)

    dfs = [
        self.rule_to_series(
            (i, r),
            index=idx,
        )
        for i, r in enumerate(self.rules)
    ]
    if len(dfs) &gt; 0:
        df = pd.concat(dfs, axis=1).T
    else:
        df = pd.DataFrame(columns=idx)

    s_cov = pd.DataFrame(
        columns=df.columns,
        data=[[self.ruleset_coverage if i == 0 else np.nan for i in range(len(df.columns))]],
        index=[&#34;ruleset coverage&#34;],
    )
    s_crit = pd.DataFrame(
        columns=df.columns,
        data=[[self.criterion if i == 0 else np.nan for i in range(len(df.columns))]],
        index=[&#34;ruleset criterion&#34;],
    )
    s_train = pd.DataFrame(
        columns=df.columns,
        data=[[self.train_set_size if i == 0 else np.nan for i in range(len(df.columns))]],
        index=[&#34;ruleset train set size&#34;],
    )
    s_test = pd.DataFrame(
        columns=df.columns,
        data=[[self.train_set_size if i == 0 else np.nan for i in range(len(df.columns))]],
        index=[&#34;ruleset test set size&#34;],
    )
    return pd.concat([df, s_cov, s_crit, s_train, s_test])</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ruleskit" href="index.html">ruleskit</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ruleskit.ruleset.traverse" href="#ruleskit.ruleset.traverse">traverse</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ruleskit.ruleset.RuleSet" href="#ruleskit.ruleset.RuleSet">RuleSet</a></code></h4>
<ul class="">
<li><code><a title="ruleskit.ruleset.RuleSet.CHECK_DUPLICATED" href="#ruleskit.ruleset.RuleSet.CHECK_DUPLICATED">CHECK_DUPLICATED</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.NLINES" href="#ruleskit.ruleset.RuleSet.NLINES">NLINES</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.STACKED_FIT" href="#ruleskit.ruleset.RuleSet.STACKED_FIT">STACKED_FIT</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.activation" href="#ruleskit.ruleset.RuleSet.activation">activation</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.activation_available" href="#ruleskit.ruleset.RuleSet.activation_available">activation_available</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.all_features_indexes" href="#ruleskit.ruleset.RuleSet.all_features_indexes">all_features_indexes</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.append" href="#ruleskit.ruleset.RuleSet.append">append</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.attributes_from_test_set" href="#ruleskit.ruleset.RuleSet.attributes_from_test_set">attributes_from_test_set</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.attributes_from_train_set" href="#ruleskit.ruleset.RuleSet.attributes_from_train_set">attributes_from_train_set</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_activation" href="#ruleskit.ruleset.RuleSet.calc_activation">calc_activation</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_criterion" href="#ruleskit.ruleset.RuleSet.calc_criterion">calc_criterion</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_criterions" href="#ruleskit.ruleset.RuleSet.calc_criterions">calc_criterions</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_predictions" href="#ruleskit.ruleset.RuleSet.calc_predictions">calc_predictions</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_signs" href="#ruleskit.ruleset.RuleSet.calc_signs">calc_signs</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_stds" href="#ruleskit.ruleset.RuleSet.calc_stds">calc_stds</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_test_set_size" href="#ruleskit.ruleset.RuleSet.calc_test_set_size">calc_test_set_size</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_test_set_sizes" href="#ruleskit.ruleset.RuleSet.calc_test_set_sizes">calc_test_set_sizes</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_train_set_size" href="#ruleskit.ruleset.RuleSet.calc_train_set_size">calc_train_set_size</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_train_set_sizes" href="#ruleskit.ruleset.RuleSet.calc_train_set_sizes">calc_train_set_sizes</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.calc_zscores" href="#ruleskit.ruleset.RuleSet.calc_zscores">calc_zscores</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.check_duplicated_rules" href="#ruleskit.ruleset.RuleSet.check_duplicated_rules">check_duplicated_rules</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.compute_self_activation" href="#ruleskit.ruleset.RuleSet.compute_self_activation">compute_self_activation</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.compute_stacked_activation" href="#ruleskit.ruleset.RuleSet.compute_stacked_activation">compute_stacked_activation</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.del_activation" href="#ruleskit.ruleset.RuleSet.del_activation">del_activation</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.del_activations" href="#ruleskit.ruleset.RuleSet.del_activations">del_activations</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.del_stacked_activations" href="#ruleskit.ruleset.RuleSet.del_stacked_activations">del_stacked_activations</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.eval" href="#ruleskit.ruleset.RuleSet.eval">eval</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.evaluate" href="#ruleskit.ruleset.RuleSet.evaluate">evaluate</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.evaluate_self_activation" href="#ruleskit.ruleset.RuleSet.evaluate_self_activation">evaluate_self_activation</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.evaluate_stacked_activations" href="#ruleskit.ruleset.RuleSet.evaluate_stacked_activations">evaluate_stacked_activations</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.fit" href="#ruleskit.ruleset.RuleSet.fit">fit</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.get_features_count" href="#ruleskit.ruleset.RuleSet.get_features_count">get_features_count</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.load" href="#ruleskit.ruleset.RuleSet.load">load</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.predict" href="#ruleskit.ruleset.RuleSet.predict">predict</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.rule_to_series" href="#ruleskit.ruleset.RuleSet.rule_to_series">rule_to_series</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.rule_type" href="#ruleskit.ruleset.RuleSet.rule_type">rule_type</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.rules" href="#ruleskit.ruleset.RuleSet.rules">rules</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.ruleset_coverage" href="#ruleskit.ruleset.RuleSet.ruleset_coverage">ruleset_coverage</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.save" href="#ruleskit.ruleset.RuleSet.save">save</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.series_to_rule" href="#ruleskit.ruleset.RuleSet.series_to_rule">series_to_rule</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.set_features_indexes" href="#ruleskit.ruleset.RuleSet.set_features_indexes">set_features_indexes</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.sort" href="#ruleskit.ruleset.RuleSet.sort">sort</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.stacked_activations_available" href="#ruleskit.ruleset.RuleSet.stacked_activations_available">stacked_activations_available</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.test_set_size" href="#ruleskit.ruleset.RuleSet.test_set_size">test_set_size</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.to_df" href="#ruleskit.ruleset.RuleSet.to_df">to_df</a></code></li>
<li><code><a title="ruleskit.ruleset.RuleSet.to_hash" href="#ruleskit.ruleset.RuleSet.to_hash">to_hash</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>